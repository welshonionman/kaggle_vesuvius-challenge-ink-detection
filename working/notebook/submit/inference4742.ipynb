{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd2026e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "is_kaggle_notebook = \"kaggle_web_client\" in sys.modules\n",
    "if is_kaggle_notebook:\n",
    "    !pip uninstall timm -y\n",
    "\n",
    "sys.path.append('/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4')\n",
    "sys.path.append('/kaggle/input/efficientnet-pytorch/EfficientNet-PyTorch-master')\n",
    "sys.path.append('/kaggle/input/timm-pytorch-image-models/pytorch-image-models-master')\n",
    "sys.path.append('/kaggle/input/segmentation-models-pytorch/segmentation_models.pytorch-master')\n",
    "sys.path.append('/kaggle/input/einops/einops-master')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0698d60b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import sys\n",
    "import warnings\n",
    "from glob import glob\n",
    "import re\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from einops import rearrange\n",
    "from segmentation_models_pytorch.decoders.unet.decoder import DecoderBlock\n",
    "from timm.models.resnet import *\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy import ndimage\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "is_kaggle_notebook = \"kaggle_web_client\" in sys.modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2689023e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    TTA = is_kaggle_notebook\n",
    "    TH=0.45\n",
    "    \n",
    "    input_dir_path = '/kaggle/input/'\n",
    "    test_dir_path = f\"/kaggle/input/vesuvius-challenge-ink-detection/test/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d7f4d6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f62b4e9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG_dataset:\n",
    "    start = 23\n",
    "    stop = 38\n",
    "    \n",
    "    stack_dir = f\"/kaggle/working/dataset_inference/\"\n",
    "    test_dataset_path = f\"/kaggle/working/dataset_inference/nonflatten/{start}-{stop}/\"\n",
    "\n",
    "    size = 256\n",
    "    tile_size = 256\n",
    "    stride = tile_size // 4\n",
    "\n",
    "    valid_batch_size = 8  # 32\n",
    "\n",
    "    in_chans = stop-start+1\n",
    "\n",
    "    # ============== augmentation =============\n",
    "    valid_aug_list = [\n",
    "        A.Resize(size, size),\n",
    "        A.Normalize(\n",
    "            mean=[0] * in_chans,\n",
    "            std=[1] * in_chans,\n",
    "            max_pixel_value=65535,\n",
    "        ),\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09630369",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_label_mask_inference(input_dir, dataset_dir, fragment_i):\n",
    "    shutil.copy(f\"{input_dir}/mask.png\", dataset_dir + f\"mask_{fragment_i}.png\")\n",
    "\n",
    "\n",
    "def split_stack_image(input_dir, dataset_dir, split=1):\n",
    "    fragment_i = input_dir.split(\"/\")[-1]\n",
    "    image_height = cv2.imread(f\"{input_dir}/surface_volume/01.tif\", -1).shape[0]\n",
    "    split_height = image_height // split\n",
    "\n",
    "    for split_i in range(split):\n",
    "        image_stack = None\n",
    "        images = []\n",
    "\n",
    "        surfaces_path = sorted(glob(f\"{input_dir}/surface_volume/*.tif\"))\n",
    "        save_npy_path = dataset_dir + f\"image_stack_{fragment_i}_{split_i}.npy\"\n",
    "        if os.path.exists(save_npy_path):\n",
    "            continue\n",
    "\n",
    "        for surface_path in tqdm(surfaces_path):\n",
    "            image = cv2.imread(surface_path, -1)\n",
    "            if split_i < split - 1:\n",
    "                image = image[split_i * split_height: (split_i + 1) * split_height, :]\n",
    "            else:\n",
    "                image = image[split_i * split_height: image_height, :]\n",
    "            images.append(image)\n",
    "            del image\n",
    "        image_stack = np.stack(images)\n",
    "\n",
    "        with open(save_npy_path, \"wb\") as f:\n",
    "            np.save(f, image_stack, allow_pickle=True)\n",
    "\n",
    "\n",
    "def extract_nonflatten_layers(input_stack_path, output_stack_path, start, stop):\n",
    "    if os.path.exists(output_stack_path):\n",
    "        return\n",
    "\n",
    "    stack = np.load(open(input_stack_path, \"rb\"))\n",
    "    stack = stack[start: stop + 1, :, :]\n",
    "\n",
    "    with open(output_stack_path, \"wb\") as f:\n",
    "        np.save(f, stack, allow_pickle=True)\n",
    "\n",
    "\n",
    "def concat_npy(save_dir, fragment_i):\n",
    "    output_path = f\"{save_dir}/{fragment_i}.npy\"\n",
    "    if os.path.exists(output_path):\n",
    "        return\n",
    "\n",
    "    npy_list = []\n",
    "    for npy in sorted(glob(f\"{save_dir}/{fragment_i}_*.npy\")):\n",
    "        npy_list.append(np.load(open(npy, 'rb')))\n",
    "\n",
    "    result = np.concatenate(npy_list, axis=1)\n",
    "\n",
    "    with open(output_path, 'wb') as f:\n",
    "        np.save(f, result, allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620d330d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if is_kaggle_notebook:\n",
    "    split = 3\n",
    "else:\n",
    "    split = 1\n",
    "    \n",
    "for input_dir in glob(f\"{CFG.test_dir_path}/*\"):\n",
    "    print(input_dir)\n",
    "    image_stack_dir = f\"{CFG_dataset.stack_dir}/nonflatten/\"\n",
    "    extract_save_dir = f\"{image_stack_dir}/{CFG_dataset.start}-{CFG_dataset.stop}/\"\n",
    "    fragment_i = input_dir.split(\"/\")[-1]\n",
    "\n",
    "    os.makedirs(CFG_dataset.stack_dir, exist_ok=True)\n",
    "    os.makedirs(image_stack_dir, exist_ok=True)\n",
    "    os.makedirs(extract_save_dir, exist_ok=True)\n",
    "\n",
    "    split_label_mask_inference(input_dir, CFG_dataset.stack_dir, fragment_i)\n",
    "    split_stack_image(input_dir, CFG_dataset.stack_dir, split)\n",
    "\n",
    "    for split_i in range(split):\n",
    "        input_stack_path = f\"{CFG_dataset.stack_dir}/image_stack_{fragment_i}_{split_i}.npy\"\n",
    "        output_stack_path = f\"{extract_save_dir}/{fragment_i}_{split_i}.npy\"\n",
    "        extract_nonflatten_layers(input_stack_path, output_stack_path, CFG_dataset.start, CFG_dataset.stop)\n",
    "\n",
    "    concat_npy(extract_save_dir, fragment_i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d434ff69",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_topomap(image_stack, x, y, range, z_buffer):\n",
    "    clipped_stack = image_stack[:, x: x + range, y: y + range]\n",
    "    clipped_stack = clipped_stack / 65535\n",
    "    clipped_stack = np.flip(clipped_stack, axis=0)\n",
    "    gauss_stack = gaussian_filter(clipped_stack, sigma=1)\n",
    "    gauss_stack = ndimage.sobel(gauss_stack, axis=0)\n",
    "    gauss_stack = gaussian_filter(gauss_stack, sigma=1)\n",
    "\n",
    "    filtered_stack = np.where(gauss_stack >= 0.5, 1, 0)  # type: ignore\n",
    "    topographic_map = np.argmax(filtered_stack, axis=0)\n",
    "\n",
    "    topographic_map = 64 - np.where(topographic_map == 0, 64, topographic_map).astype(\"uint8\")\n",
    "    topographic_map = cv2.medianBlur(topographic_map, 15)\n",
    "\n",
    "    is_idx = np.indices(clipped_stack.shape)\n",
    "    flattened_stack = clipped_stack[(is_idx[0] + topographic_map - z_buffer) % clipped_stack.shape[0], is_idx[1], is_idx[2], ]\n",
    "    flattened_stack = (np.flip(flattened_stack, axis=0) * 65536).astype(\"uint16\")\n",
    "\n",
    "    return topographic_map\n",
    "\n",
    "\n",
    "def create_whole_topomap(image_stack_path, output_topography_path):\n",
    "    if os.path.exists(output_topography_path):\n",
    "        return\n",
    "\n",
    "    image_stack = np.load(open(image_stack_path, \"rb\"))\n",
    "\n",
    "    _, image_stack_x, image_stack_y = image_stack.shape\n",
    "    output_topography = np.zeros(image_stack.shape[1:])\n",
    "    for x in range(0, image_stack_x, 250):\n",
    "        for y in range(0, image_stack_y, 250):\n",
    "            topographic_map = create_topomap(image_stack, x, y, 250, 5)\n",
    "            output_topography[x: x + 250, y: y + 250] = topographic_map\n",
    "\n",
    "    cv2.imwrite(output_topography_path, output_topography)\n",
    "\n",
    "\n",
    "def concat_topo(save_dir, fragment_i):\n",
    "    topo_list = []\n",
    "    for topo in sorted(glob(f\"{save_dir}/topography_{fragment_i}_*.png\")):\n",
    "        topo_list.append(cv2.imread(topo, -1))\n",
    "    result = np.concatenate(topo_list, axis=0)\n",
    "    output_topo_fname = f\"{save_dir}/topography_{fragment_i}.png\"\n",
    "    print(output_topo_fname)\n",
    "    cv2.imwrite(output_topo_fname, result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648f0785",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for image_stack_path in glob(f\"{CFG_dataset.stack_dir}/image_stack*\"):\n",
    "    fragment_i = image_stack_path.split(\"/\")[-1].split(\"_\")[2]\n",
    "    split_i = image_stack_path.split(\"/\")[-1].split(\"_\")[3].split(\".\")[0]\n",
    "    output_topography_path = os.path.join(CFG_dataset.stack_dir + f\"topography_{fragment_i}_{split_i}.png\")\n",
    "    create_whole_topomap(image_stack_path, output_topography_path)\n",
    "\n",
    "\n",
    "fragment_list = [i.split(\"_\")[-1].split(\".\")[0] for i in glob(f\"{CFG_dataset.stack_dir}/mask*\")]\n",
    "\n",
    "for fragment_i in fragment_list:\n",
    "    concat_topo(CFG_dataset.stack_dir, fragment_i)\n",
    "    topography = cv2.imread(f\"{CFG_dataset.stack_dir}/topography_{fragment_i}.png\", 0)\n",
    "    new_mask = (topography > 0).astype(\"uint8\")*255\n",
    "    cv2.imwrite(f\"{CFG_dataset.stack_dir}/mask_{fragment_i}.png\", new_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb1e128",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if is_kaggle_notebook:\n",
    "    for path in glob(f\"{CFG_dataset.stack_dir}/**/*.*\", recursive=True):\n",
    "        if re.search(r\"_\\d\", path):\n",
    "            os.remove(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c688eed",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262e3b16",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_image(fragment_id):\n",
    "    image_stack = np.load(open(f\"{CFG_dataset.test_dataset_path}/{fragment_id}.npy\", 'rb'))\n",
    "\n",
    "    pad0 = (CFG_dataset.tile_size - image_stack.shape[1] % CFG_dataset.tile_size)\n",
    "    pad1 = (CFG_dataset.tile_size - image_stack.shape[2] % CFG_dataset.tile_size)\n",
    "\n",
    "    image_stack = np.pad(image_stack, [(0, 0), (0, pad0), (0, pad1)], constant_values=0)\n",
    "    image_stack = image_stack.transpose((1, 2, 0))\n",
    "    image_stack = preprocess(image_stack)\n",
    "\n",
    "    return image_stack\n",
    "\n",
    "\n",
    "def get_transforms(data, cfg):\n",
    "    aug = A.Compose(cfg.valid_aug_list)\n",
    "    return aug\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, cfg, labels=None, transform=None):\n",
    "        self.images = images\n",
    "        self.cfg = cfg\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        data = self.transform(image=image)\n",
    "        image = data['image']\n",
    "        return image\n",
    "\n",
    "\n",
    "def make_test_dataset(fragment_id):\n",
    "    test_images = read_image(fragment_id)\n",
    "    x1_list = list(range(0, test_images.shape[1]-CFG_dataset.tile_size+1, CFG_dataset.stride))\n",
    "    y1_list = list(range(0, test_images.shape[0]-CFG_dataset.tile_size+1, CFG_dataset.stride))\n",
    "\n",
    "    test_images_list = []\n",
    "    xyxys = []\n",
    "    for y1 in y1_list:\n",
    "        for x1 in x1_list:\n",
    "            y2 = y1 + CFG_dataset.tile_size\n",
    "            x2 = x1 + CFG_dataset.tile_size\n",
    "\n",
    "            test_images_list.append(test_images[y1:y2, x1:x2])\n",
    "            xyxys.append((x1, y1, x2, y2))\n",
    "\n",
    "    test_dataset = CustomDataset(test_images_list, CFG_dataset, transform=get_transforms(data='valid', cfg=CFG_dataset))\n",
    "\n",
    "    test_loader = DataLoader(test_dataset,\n",
    "                             batch_size=CFG_dataset.valid_batch_size,\n",
    "                             shuffle=False,\n",
    "                             num_workers=4, pin_memory=True, drop_last=False)\n",
    "    return test_loader, xyxys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365d70bf",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_binary_mask(mask_path, tile_size):\n",
    "    binary_mask = cv2.imread(mask_path, 0)\n",
    "    binary_mask = binary_mask / 255 # type: ignore\n",
    "    binary_mask = binary_mask.astype(int)\n",
    "\n",
    "    pad0 = (tile_size - binary_mask.shape[0] % tile_size)\n",
    "    pad1 = (tile_size - binary_mask.shape[1] % tile_size)\n",
    "\n",
    "    binary_mask = np.pad(binary_mask, [(0, pad0), (0, pad1)], constant_values=0)\n",
    "    return binary_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7ef8ba",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec33fa72",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f50160",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-04T04:51:23.865123Z",
     "iopub.status.busy": "2023-04-04T04:51:23.864743Z",
     "iopub.status.idle": "2023-04-04T04:51:23.87814Z",
     "shell.execute_reply": "2023-04-04T04:51:23.877181Z",
     "shell.execute_reply.started": "2023-04-04T04:51:23.86506Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UnetDecoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channel,\n",
    "                 skip_channel,\n",
    "                 out_channel,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.center = nn.Identity()\n",
    "\n",
    "        i_channel = [in_channel,] + out_channel[:-1]\n",
    "        s_channel = skip_channel\n",
    "        o_channel = out_channel\n",
    "        block = [\n",
    "            DecoderBlock(i, s, o, use_batchnorm=True, attention_type=None)\n",
    "            for i, s, o in zip(i_channel, s_channel, o_channel)\n",
    "        ]\n",
    "        self.block = nn.ModuleList(block)\n",
    "\n",
    "    def forward(self, feature, skip):\n",
    "        d = self.center(feature)\n",
    "        decode = []\n",
    "        for i, block in enumerate(self.block):\n",
    "            s = skip[i]\n",
    "            d = block(d, s)\n",
    "            decode.append(d)\n",
    "\n",
    "        last = d\n",
    "        return last, decode\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.output_type = ['inference', 'loss']\n",
    "\n",
    "        conv_dim = 64\n",
    "        encoder1_dim = [conv_dim, 64, 128, 256, 512, ]\n",
    "        decoder1_dim = [256, 128, 64, 64,]\n",
    "\n",
    "        self.encoder1 = resnet34d(pretrained=False, in_chans=CFG_model.crop_depth)\n",
    "\n",
    "        self.decoder1 = UnetDecoder(\n",
    "            in_channel=encoder1_dim[-1],\n",
    "            skip_channel=encoder1_dim[:-1][::-1],\n",
    "            out_channel=decoder1_dim,\n",
    "        )\n",
    "        # -- pool attention weight\n",
    "        self.weight1 = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(dim, dim, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "            ) for dim in encoder1_dim\n",
    "        ])\n",
    "        self.logit1 = nn.Conv2d(decoder1_dim[-1], 1, kernel_size=1)\n",
    "\n",
    "        # --------------------------------\n",
    "        #\n",
    "        encoder2_dim = [64, 128, 256, 512]\n",
    "        decoder2_dim = [128, 64, 32, ]\n",
    "        self.encoder2 = resnet10t(pretrained=False, in_chans=decoder1_dim[-1])\n",
    "\n",
    "        self.decoder2 = UnetDecoder(\n",
    "            in_channel=encoder2_dim[-1],\n",
    "            skip_channel=encoder2_dim[:-1][::-1],\n",
    "            out_channel=decoder2_dim,\n",
    "        )\n",
    "        self.logit2 = nn.Conv2d(decoder2_dim[-1], 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        v = batch\n",
    "        B, C, H, W = v.shape\n",
    "        random_shift = random.randint(CFG_model.random_shift, CFG_model.random_shift)\n",
    "        vv = [\n",
    "            v[:, i+random_shift:i+random_shift+CFG_model.crop_depth] for i in CFG_model.layer_shift\n",
    "        ]\n",
    "        K = len(vv)\n",
    "        x = torch.cat(vv, 0)\n",
    "        # x = v\n",
    "\n",
    "        # ----------------------\n",
    "        encoder = []\n",
    "        e = self.encoder1\n",
    "        x = e.conv1(x)\n",
    "        x = e.bn1(x)\n",
    "        x = e.act1(x)\n",
    "        encoder.append(x)\n",
    "        x = F.avg_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = e.layer1(x)\n",
    "        encoder.append(x)\n",
    "        x = e.layer2(x)\n",
    "        encoder.append(x)\n",
    "        x = e.layer3(x)\n",
    "        encoder.append(x)\n",
    "        x = e.layer4(x)\n",
    "        encoder.append(x)\n",
    "        # print('encoder', [f.shape for f in encoder])\n",
    "\n",
    "        for i in range(len(encoder)):\n",
    "            e = encoder[i]\n",
    "            # e = F.avg_pool2d(e, kernel_size=4, stride=4)\n",
    "            f = self.weight1[i](e)\n",
    "            _, c, h, w = e.shape\n",
    "            f = rearrange(f, '(K B) c h w -> B K c h w', K=K, B=B, h=h, w=w)  #\n",
    "            e = rearrange(e, '(K B) c h w -> B K c h w', K=K, B=B, h=h, w=w)  #\n",
    "            w = F.softmax(f, 1)\n",
    "            e = (w * e).sum(1)\n",
    "            encoder[i] = e\n",
    "\n",
    "        feature = encoder[-1]\n",
    "        skip = encoder[:-1][::-1]\n",
    "        last, decoder = self.decoder1(feature, skip)\n",
    "        logit1 = self.logit1(last)\n",
    "\n",
    "        # ----------------------\n",
    "        x = last  # .detach()\n",
    "        # x = F.avg_pool2d(x,kernel_size=2,stride=2)\n",
    "        encoder = []\n",
    "        e = self.encoder2\n",
    "        x = e.layer1(x)\n",
    "        encoder.append(x)\n",
    "        x = e.layer2(x)\n",
    "        encoder.append(x)\n",
    "        x = e.layer3(x)\n",
    "        encoder.append(x)\n",
    "        x = e.layer4(x)\n",
    "        encoder.append(x)\n",
    "\n",
    "        feature = encoder[-1]\n",
    "        skip = encoder[:-1][::-1]\n",
    "        last, decoder = self.decoder2(feature, skip)\n",
    "        logit2 = self.logit2(last)\n",
    "        logit1 = F.interpolate(logit1, size=(H, W), mode='bilinear', align_corners=False, antialias=True)\n",
    "        logit2 = F.interpolate(logit2, size=(H, W), mode='bilinear', align_corners=False, antialias=True)\n",
    "\n",
    "        return logit1, logit2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6741767e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def TTA(x: torch.Tensor, model: nn.Module, is_TTA):\n",
    "    if is_TTA:\n",
    "        shape = x.shape\n",
    "        x = [x, *[torch.rot90(x, k=i, dims=(-2, -1)) for i in range(1, 4)]] # type: ignore\n",
    "        x = torch.cat(x, dim=0)\n",
    "        x = model(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        x = x.reshape(4, shape[0], *shape[2:])\n",
    "        x = [torch.rot90(x[i], k=-i, dims=(-2, -1)) for i in range(4)] # type: ignore\n",
    "        x = torch.stack(x, dim=0)\n",
    "        return x.mean(0)\n",
    "    else:\n",
    "        x = model(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7ba5e2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EnsembleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.ModuleList()\n",
    "        for fold in range(CFG_model.fold):\n",
    "            _model = Net()\n",
    "\n",
    "            if os.path.exists(f'{CFG.input_dir_path}/{CFG_model.exp_name}/{CFG_model.exp_name}_fold{fold}.pth'):\n",
    "                model_path = f'{CFG.input_dir_path}/{CFG_model.exp_name}/{CFG_model.exp_name}_fold{fold}.pth'\n",
    "            else:\n",
    "                model_path = f'./{CFG_model.exp_name}/{CFG_model.exp_name}_fold{fold}.pth'\n",
    "            print(model_path)\n",
    "            state = torch.load(model_path)['model']\n",
    "            _model.load_state_dict(state)\n",
    "            _model.eval()\n",
    "\n",
    "            self.model.append(_model)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        output=[]\n",
    "        for m in self.model:\n",
    "            output.append(m(x)[0])\n",
    "        output=torch.stack(output,dim=0).mean(0)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acd60e4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "for fragment_id in sorted(os.listdir(CFG.test_dir_path)):\n",
    "    results[fragment_id]=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a8db09",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f7bb34a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# main1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ae9887",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG_model:\n",
    "    # ============== comp exp name =============\n",
    "    exp_name = \"model3\"\n",
    "    fold = 5\n",
    "    # ============== model cfg =============\n",
    "    crop_depth = 6\n",
    "    random_shift = 1\n",
    "    layer_shift = [0, 2, 4, 6, 8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92aa3de1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    # for layer in range(image.shape[2]):\n",
    "    #     image_=image[:,:,layer]\n",
    "    #     clahe = cv2.createCLAHE(clipLimit=2, tileGridSize=(8,8))\n",
    "    #     cl1 = clahe.apply(image_)\n",
    "    #     image[:,:,layer]=cl1\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc10d5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-04T04:51:23.892968Z",
     "iopub.status.busy": "2023-04-04T04:51:23.892497Z",
     "iopub.status.idle": "2023-04-04T04:51:23.908Z",
     "shell.execute_reply": "2023-04-04T04:51:23.906772Z",
     "shell.execute_reply.started": "2023-04-04T04:51:23.892927Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_gpus = torch.cuda.device_count()\n",
    "device_ids = list(range(num_gpus))\n",
    "\n",
    "model = EnsembleModel()\n",
    "model = nn.DataParallel(model, device_ids=device_ids)\n",
    "model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d087f814",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for fragment_id in sorted(os.listdir(CFG.test_dir_path)):\n",
    "\n",
    "    test_loader, xyxys = make_test_dataset(fragment_id)\n",
    "\n",
    "    mask_path = CFG_dataset.stack_dir + f\"/mask_{fragment_id}.png\"\n",
    "    binary_mask = make_binary_mask(mask_path, CFG_dataset.tile_size)\n",
    "    ori_h, ori_w = cv2.imread(mask_path,-1).shape\n",
    "    mask_pred = np.zeros(binary_mask.shape)\n",
    "    mask_count = np.zeros(binary_mask.shape)\n",
    "\n",
    "    for step, (images) in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
    "        images = images.cuda()\n",
    "        batch_size = images.size(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_preds = TTA(images, model, CFG.TTA).cpu().numpy()\n",
    "\n",
    "        start_idx = step*CFG_dataset.valid_batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "        for i, (x1, y1, x2, y2) in enumerate(xyxys[start_idx:end_idx]):\n",
    "            mask_pred[y1:y2, x1:x2] += y_preds[i].reshape(mask_pred[y1:y2, x1:x2].shape)\n",
    "            mask_count[y1:y2, x1:x2] += np.ones((CFG_dataset.tile_size, CFG_dataset.tile_size))\n",
    "\n",
    "    mask_pred /= mask_count\n",
    "    del test_loader\n",
    "\n",
    "    mask_pred = mask_pred[:ori_h, :ori_w]\n",
    "    binary_mask = binary_mask[:ori_h, :ori_w]\n",
    "\n",
    "    mask_pred *= binary_mask\n",
    "    # results.append((fragment_id, mask_pred))\n",
    "    results[fragment_id].append(mask_pred)\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4969444c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "faf5ec37",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# main2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7d68cd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG_model:\n",
    "    # ============== comp exp name =============\n",
    "    exp_name = \"model13\"\n",
    "    fold = 5\n",
    "    # ============== model cfg =============\n",
    "    crop_depth = 6\n",
    "    random_shift = 1\n",
    "    layer_shift = [0, 2, 4, 6, 8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe648d0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    # for layer in range(image.shape[2]):\n",
    "    #     image_=image[:,:,layer]\n",
    "    #     clahe = cv2.createCLAHE(clipLimit=2, tileGridSize=(8,8))\n",
    "    #     cl1 = clahe.apply(image_)\n",
    "    #     image[:,:,layer]=cl1\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d30b93",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_gpus = torch.cuda.device_count()\n",
    "device_ids = list(range(num_gpus))\n",
    "\n",
    "model = EnsembleModel()\n",
    "model = nn.DataParallel(model, device_ids=device_ids)\n",
    "model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9154ab",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for fragment_id in sorted(os.listdir(CFG.test_dir_path)):\n",
    "\n",
    "    test_loader, xyxys = make_test_dataset(fragment_id)\n",
    "\n",
    "    mask_path = CFG_dataset.stack_dir + f\"/mask_{fragment_id}.png\"\n",
    "    binary_mask = make_binary_mask(mask_path, CFG_dataset.tile_size)\n",
    "    ori_h, ori_w = cv2.imread(mask_path,-1).shape\n",
    "    mask_pred = np.zeros(binary_mask.shape)\n",
    "    mask_count = np.zeros(binary_mask.shape)\n",
    "\n",
    "    for step, (images) in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
    "        images = images.cuda()\n",
    "        batch_size = images.size(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_preds = TTA(images, model, CFG.TTA).cpu().numpy()\n",
    "\n",
    "        start_idx = step*CFG_dataset.valid_batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "        for i, (x1, y1, x2, y2) in enumerate(xyxys[start_idx:end_idx]):\n",
    "            mask_pred[y1:y2, x1:x2] += y_preds[i].reshape(mask_pred[y1:y2, x1:x2].shape)\n",
    "            mask_count[y1:y2, x1:x2] += np.ones((CFG_dataset.tile_size, CFG_dataset.tile_size))\n",
    "\n",
    "    mask_pred /= mask_count\n",
    "    del test_loader\n",
    "\n",
    "    mask_pred = mask_pred[:ori_h, :ori_w]\n",
    "    binary_mask = binary_mask[:ori_h, :ori_w]\n",
    "\n",
    "    mask_pred *= binary_mask\n",
    "    # results.append((fragment_id, mask_pred))\n",
    "    results[fragment_id].append(mask_pred)\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d35ab71",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcb33fec",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# main3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c60f29",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG_model:\n",
    "    # ============== comp exp name =============\n",
    "    exp_name = \"model19\"\n",
    "    fold = 5\n",
    "    # ============== model cfg =============\n",
    "    crop_depth = 6\n",
    "    random_shift = 1\n",
    "    layer_shift = [0, 2, 4, 6, 8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442a6d60",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UnetDecoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channel,\n",
    "                 skip_channel,\n",
    "                 out_channel,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.center = nn.Identity()\n",
    "\n",
    "        i_channel = [in_channel,] + out_channel[:-1]\n",
    "        s_channel = skip_channel\n",
    "        o_channel = out_channel\n",
    "        block = [\n",
    "            DecoderBlock(i, s, o, use_batchnorm=True, attention_type=None)\n",
    "            for i, s, o in zip(i_channel, s_channel, o_channel)\n",
    "        ]\n",
    "        self.block = nn.ModuleList(block)\n",
    "\n",
    "    def forward(self, feature, skip):\n",
    "        d = self.center(feature)\n",
    "        decode = []\n",
    "        for i, block in enumerate(self.block):\n",
    "            s = skip[i]\n",
    "            d = block(d, s)\n",
    "            decode.append(d)\n",
    "\n",
    "        last = d\n",
    "        return last, decode\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.output_type = ['inference', 'loss']\n",
    "\n",
    "        conv_dim = 64\n",
    "        encoder1_dim = [conv_dim, 64, 128, 256, 512, ]\n",
    "        decoder1_dim = [256, 128, 64, 64,]\n",
    "\n",
    "        self.encoder1 = resnet34d(pretrained=False, in_chans=CFG_model.crop_depth)\n",
    "\n",
    "        self.decoder1 = UnetDecoder(\n",
    "            in_channel=encoder1_dim[-1],\n",
    "            skip_channel=encoder1_dim[:-1][::-1],\n",
    "            out_channel=decoder1_dim,\n",
    "        )\n",
    "        # -- pool attention weight\n",
    "        self.weight1 = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(dim, dim, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "            ) for dim in encoder1_dim\n",
    "        ])\n",
    "        self.logit1 = nn.Conv2d(decoder1_dim[-1], 1, kernel_size=1)\n",
    "\n",
    "        # --------------------------------\n",
    "        #\n",
    "        encoder2_dim = [256, 512, 1024, 2048]\n",
    "        decoder2_dim = [512, 256, 128, ]\n",
    "        self.encoder2 = resnet14t(pretrained=False, in_chans=decoder1_dim[-1])\n",
    "\n",
    "        self.decoder2 = UnetDecoder(\n",
    "            in_channel=encoder2_dim[-1],\n",
    "            skip_channel=encoder2_dim[:-1][::-1],\n",
    "            out_channel=decoder2_dim,\n",
    "        )\n",
    "        self.logit2 = nn.Conv2d(decoder2_dim[-1], 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        v = batch\n",
    "        B, C, H, W = v.shape\n",
    "        random_shift = random.randint(CFG_model.random_shift, CFG_model.random_shift)\n",
    "        vv = [\n",
    "            v[:, i+random_shift:i+random_shift+CFG_model.crop_depth] for i in CFG_model.layer_shift\n",
    "        ]\n",
    "        K = len(vv)\n",
    "        x = torch.cat(vv, 0)\n",
    "        # x = v\n",
    "\n",
    "        # ----------------------\n",
    "        encoder = []\n",
    "        e = self.encoder1\n",
    "        x = e.conv1(x)\n",
    "        x = e.bn1(x)\n",
    "        x = e.act1(x)\n",
    "        encoder.append(x)\n",
    "        x = F.avg_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = e.layer1(x)\n",
    "        encoder.append(x)\n",
    "        x = e.layer2(x)\n",
    "        encoder.append(x)\n",
    "        x = e.layer3(x)\n",
    "        encoder.append(x)\n",
    "        x = e.layer4(x)\n",
    "        encoder.append(x)\n",
    "        # print('encoder', [f.shape for f in encoder])\n",
    "\n",
    "        for i in range(len(encoder)):\n",
    "            e = encoder[i]\n",
    "            # e = F.avg_pool2d(e, kernel_size=4, stride=4)\n",
    "            f = self.weight1[i](e)\n",
    "            _, c, h, w = e.shape\n",
    "            f = rearrange(f, '(K B) c h w -> B K c h w', K=K, B=B, h=h, w=w)  #\n",
    "            e = rearrange(e, '(K B) c h w -> B K c h w', K=K, B=B, h=h, w=w)  #\n",
    "            w = F.softmax(f, 1)\n",
    "            e = (w * e).sum(1)\n",
    "            encoder[i] = e\n",
    "\n",
    "        feature = encoder[-1]\n",
    "        skip = encoder[:-1][::-1]\n",
    "        last, decoder = self.decoder1(feature, skip)\n",
    "        logit1 = self.logit1(last)\n",
    "\n",
    "        # ----------------------\n",
    "        x = last  # .detach()\n",
    "        # x = F.avg_pool2d(x,kernel_size=2,stride=2)\n",
    "        encoder = []\n",
    "        e = self.encoder2\n",
    "        x = e.layer1(x)\n",
    "        encoder.append(x)\n",
    "        x = e.layer2(x)\n",
    "        encoder.append(x)\n",
    "        x = e.layer3(x)\n",
    "        encoder.append(x)\n",
    "        x = e.layer4(x)\n",
    "        encoder.append(x)\n",
    "\n",
    "        feature = encoder[-1]\n",
    "        skip = encoder[:-1][::-1]\n",
    "        last, decoder = self.decoder2(feature, skip)\n",
    "        logit2 = self.logit2(last)\n",
    "        logit1 = F.interpolate(logit1, size=(H, W), mode='bilinear', align_corners=False, antialias=True)\n",
    "        logit2 = F.interpolate(logit2, size=(H, W), mode='bilinear', align_corners=False, antialias=True)\n",
    "\n",
    "        return logit1, logit2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7943264",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    # for layer in range(image.shape[2]):\n",
    "    #     image_=image[:,:,layer]\n",
    "    #     clahe = cv2.createCLAHE(clipLimit=2, tileGridSize=(8,8))\n",
    "    #     cl1 = clahe.apply(image_)\n",
    "    #     image[:,:,layer]=cl1\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54992b81",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_gpus = torch.cuda.device_count()\n",
    "device_ids = list(range(num_gpus))\n",
    "\n",
    "model = EnsembleModel()\n",
    "model = nn.DataParallel(model, device_ids=device_ids)\n",
    "model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5ba23b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for fragment_id in sorted(os.listdir(CFG.test_dir_path)):\n",
    "\n",
    "    test_loader, xyxys = make_test_dataset(fragment_id)\n",
    "\n",
    "    mask_path = CFG_dataset.stack_dir + f\"/mask_{fragment_id}.png\"\n",
    "    binary_mask = make_binary_mask(mask_path, CFG_dataset.tile_size)\n",
    "    ori_h, ori_w = cv2.imread(mask_path,-1).shape\n",
    "    mask_pred = np.zeros(binary_mask.shape)\n",
    "    mask_count = np.zeros(binary_mask.shape)\n",
    "\n",
    "    for step, (images) in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
    "        images = images.cuda()\n",
    "        batch_size = images.size(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_preds = TTA(images, model, CFG.TTA).cpu().numpy()\n",
    "\n",
    "        start_idx = step*CFG_dataset.valid_batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "        for i, (x1, y1, x2, y2) in enumerate(xyxys[start_idx:end_idx]):\n",
    "            mask_pred[y1:y2, x1:x2] += y_preds[i].reshape(mask_pred[y1:y2, x1:x2].shape)\n",
    "            mask_count[y1:y2, x1:x2] += np.ones((CFG_dataset.tile_size, CFG_dataset.tile_size))\n",
    "\n",
    "    mask_pred /= mask_count\n",
    "    del test_loader\n",
    "\n",
    "    mask_pred = mask_pred[:ori_h, :ori_w]\n",
    "    binary_mask = binary_mask[:ori_h, :ori_w]\n",
    "\n",
    "    mask_pred *= binary_mask\n",
    "    # results.append((fragment_id, mask_pred))\n",
    "    results[fragment_id].append(mask_pred)\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7000be10",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a09b89a2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "\n",
    "# submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c60504c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ref.: https://www.kaggle.com/stainsby/fast-tested-rle\n",
    "def rle(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.flatten()\n",
    "    # pixels = (pixels >= thr).astype(int)\n",
    "\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39782e18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-04T05:04:59.79253Z",
     "iopub.status.busy": "2023-04-04T05:04:59.791024Z",
     "iopub.status.idle": "2023-04-04T05:04:59.80219Z",
     "shell.execute_reply": "2023-04-04T05:04:59.801265Z",
     "shell.execute_reply.started": "2023-04-04T05:04:59.792484Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for fragment_id, preds in results.items():\n",
    "    pred = np.array(preds).mean(axis=0)\n",
    "\n",
    "    pred_thresh = (pred >= CFG.TH).astype(\"uint8\")\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    pred_thresh = cv2.dilate(pred_thresh,kernel,iterations = 4)\n",
    "    pred_thresh = cv2.erode(pred_thresh,kernel,iterations = 8)\n",
    "    pred_thresh = cv2.dilate(pred_thresh,kernel,iterations = 8)\n",
    "    pred_thresh = cv2.erode(pred_thresh,kernel,iterations = 8)\n",
    "    pred_thresh = cv2.dilate(pred_thresh,kernel,iterations = 8)\n",
    "    pred_thresh = cv2.erode(pred_thresh,kernel,iterations = 8)\n",
    "    pred_thresh = cv2.dilate(pred_thresh,kernel,iterations = 8)\n",
    "    pred_thresh = cv2.erode(pred_thresh,kernel,iterations = 8)\n",
    "    pred_thresh = cv2.dilate(pred_thresh,kernel,iterations = 8)\n",
    "    pred_thresh = cv2.erode(pred_thresh,kernel,iterations = 8)\n",
    "    pred_thresh = cv2.dilate(pred_thresh,kernel,iterations = 8)\n",
    "    pred_thresh = cv2.erode(pred_thresh,kernel,iterations = 4)\n",
    "    \n",
    "    inklabels_rle = rle(pred_thresh)\n",
    "    results[fragment_id] = inklabels_rle\n",
    "\n",
    "\n",
    "sub = pd.DataFrame(results.items(), columns=['Id', 'Predicted'])\n",
    "sample_sub = pd.read_csv(\"/kaggle/input/vesuvius-challenge-ink-detection/sample_submission.csv\")\n",
    "sample_sub = pd.merge(sample_sub[['Id']], sub, on='Id', how='left')\n",
    "if is_kaggle_notebook:\n",
    "    sample_sub.to_csv(\"submission.csv\", index=False)\n",
    "sample_sub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50a2103",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d25cfd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-06-14T11:30:49.534668",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
