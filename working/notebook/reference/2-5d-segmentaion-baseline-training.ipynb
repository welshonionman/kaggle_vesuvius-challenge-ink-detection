{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## summary\n\n* 2.5d segmentation\n    *  segmentation_models_pytorch \n    *  Unet\n* use only 6 slices in the middle\n* slide inference","metadata":{}},{"cell_type":"code","source":"\nfrom sklearn.metrics import roc_auc_score, accuracy_score, f1_score, log_loss\nimport pickle\nfrom torch.utils.data import DataLoader\nfrom torch.cuda.amp import autocast, GradScaler\nimport warnings\nimport sys\nimport pandas as pd\nimport os\nimport gc\nimport sys\nimport math\nimport time\nimport random\nimport shutil\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\nimport cv2\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nfrom tqdm.auto import tqdm\nfrom functools import partial\n\nimport argparse\nimport importlib\nimport torch\nimport torch.nn as nn\nfrom torch.optim import Adam, SGD, AdamW\n\nimport datetime","metadata":{"execution":{"iopub.status.busy":"2023-04-04T05:50:04.941229Z","iopub.execute_input":"2023-04-04T05:50:04.942067Z","iopub.status.idle":"2023-04-04T05:50:08.854436Z","shell.execute_reply.started":"2023-04-04T05:50:04.942033Z","shell.execute_reply":"2023-04-04T05:50:08.853221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sys.path.append('/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4')\n# sys.path.append('/kaggle/input/efficientnet-pytorch/EfficientNet-PyTorch-master')\n# sys.path.append('/kaggle/input/timm-pytorch-image-models/pytorch-image-models-master')\n# sys.path.append('/kaggle/input/segmentation-models-pytorch/segmentation_models.pytorch-master')","metadata":{"execution":{"iopub.status.busy":"2023-04-04T05:50:08.856941Z","iopub.execute_input":"2023-04-04T05:50:08.857552Z","iopub.status.idle":"2023-04-04T05:50:08.86897Z","shell.execute_reply.started":"2023-04-04T05:50:08.857508Z","shell.execute_reply":"2023-04-04T05:50:08.866753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install segmentation_models_pytorch","metadata":{"execution":{"iopub.status.busy":"2023-04-04T05:50:08.871687Z","iopub.execute_input":"2023-04-04T05:50:08.872372Z","iopub.status.idle":"2023-04-04T05:50:23.842146Z","shell.execute_reply.started":"2023-04-04T05:50:08.87233Z","shell.execute_reply":"2023-04-04T05:50:23.840897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import segmentation_models_pytorch as smp","metadata":{"execution":{"iopub.status.busy":"2023-04-04T05:50:23.846745Z","iopub.execute_input":"2023-04-04T05:50:23.847082Z","iopub.status.idle":"2023-04-04T05:50:26.322624Z","shell.execute_reply.started":"2023-04-04T05:50:23.847045Z","shell.execute_reply":"2023-04-04T05:50:26.321448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install warmup_scheduler","metadata":{"execution":{"iopub.status.busy":"2023-04-04T05:50:26.324645Z","iopub.execute_input":"2023-04-04T05:50:26.325092Z","iopub.status.idle":"2023-04-04T05:50:37.363192Z","shell.execute_reply.started":"2023-04-04T05:50:26.325042Z","shell.execute_reply":"2023-04-04T05:50:37.361806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom torch.utils.data import DataLoader, Dataset\nimport cv2\nimport torch\nimport os\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import ImageOnlyTransform","metadata":{"execution":{"iopub.status.busy":"2023-04-04T05:50:37.365274Z","iopub.execute_input":"2023-04-04T05:50:37.365713Z","iopub.status.idle":"2023-04-04T05:50:38.190783Z","shell.execute_reply.started":"2023-04-04T05:50:37.365653Z","shell.execute_reply":"2023-04-04T05:50:38.189664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## config","metadata":{}},{"cell_type":"code","source":"import os\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nclass CFG:\n    # ============== comp exp name =============\n    comp_name = 'vesuvius'\n\n    # comp_dir_path = './'\n    comp_dir_path = '/kaggle/input/'\n    comp_folder_name = 'vesuvius-challenge-ink-detection'\n    # comp_dataset_path = f'{comp_dir_path}datasets/{comp_folder_name}/'\n    comp_dataset_path = f'{comp_dir_path}{comp_folder_name}/'\n    \n    exp_name = 'vesuvius_2d_slide_exp002'\n\n    # ============== pred target =============\n    target_size = 1\n\n    # ============== model cfg =============\n    model_name = 'Unet'\n    backbone = 'efficientnet-b0'\n    # backbone = 'se_resnext50_32x4d'\n\n    in_chans = 6 # 65\n    # ============== training cfg =============\n    size = 224\n    tile_size = 224\n    stride = tile_size // 2\n\n    train_batch_size = 16 # 32\n    valid_batch_size = train_batch_size * 2\n    use_amp = True\n\n    scheduler = 'GradualWarmupSchedulerV2'\n    # scheduler = 'CosineAnnealingLR'\n    epochs = 15 # 30\n\n    # adamW warmupあり\n    warmup_factor = 10\n    # lr = 1e-4 / warmup_factor\n    lr = 1e-4 / warmup_factor\n\n    # ============== fold =============\n    valid_id = 1\n\n    # objective_cv = 'binary'  # 'binary', 'multiclass', 'regression'\n    metric_direction = 'maximize'  # maximize, 'minimize'\n    # metrics = 'dice_coef'\n\n    # ============== fixed =============\n    pretrained = True\n    inf_weight = 'best'  # 'best'\n\n    min_lr = 1e-6\n    weight_decay = 1e-6\n    max_grad_norm = 1000\n\n    print_freq = 50\n    num_workers = 4\n\n    seed = 42\n\n    # ============== set dataset path =============\n    print('set dataset path')\n\n    outputs_path = f'/kaggle/working/outputs/{comp_name}/{exp_name}/'\n\n    submission_dir = outputs_path + 'submissions/'\n    submission_path = submission_dir + f'submission_{exp_name}.csv'\n\n    model_dir = outputs_path + \\\n        f'{comp_name}-models/'\n\n    figures_dir = outputs_path + 'figures/'\n\n    log_dir = outputs_path + 'logs/'\n    log_path = log_dir + f'{exp_name}.txt'\n\n    # ============== augmentation =============\n    train_aug_list = [\n        # A.RandomResizedCrop(\n        #     size, size, scale=(0.85, 1.0)),\n        A.Resize(size, size),\n        A.HorizontalFlip(p=0.5),\n        A.VerticalFlip(p=0.5),\n        A.RandomBrightnessContrast(p=0.75),\n        A.ShiftScaleRotate(p=0.75),\n        A.OneOf([\n                A.GaussNoise(var_limit=[10, 50]),\n                A.GaussianBlur(),\n                A.MotionBlur(),\n                ], p=0.4),\n        A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.5),\n        A.CoarseDropout(max_holes=1, max_width=int(size * 0.3), max_height=int(size * 0.3), \n                        mask_fill_value=0, p=0.5),\n        # A.Cutout(max_h_size=int(size * 0.6),\n        #          max_w_size=int(size * 0.6), num_holes=1, p=1.0),\n        A.Normalize(\n            mean= [0] * in_chans,\n            std= [1] * in_chans\n        ),\n        ToTensorV2(transpose_mask=True),\n    ]\n\n    valid_aug_list = [\n        A.Resize(size, size),\n        A.Normalize(\n            mean= [0] * in_chans,\n            std= [1] * in_chans\n        ),\n        ToTensorV2(transpose_mask=True),\n    ]\n","metadata":{"execution":{"iopub.status.busy":"2023-04-04T05:50:38.192696Z","iopub.execute_input":"2023-04-04T05:50:38.19323Z","iopub.status.idle":"2023-04-04T05:50:38.211206Z","shell.execute_reply.started":"2023-04-04T05:50:38.193193Z","shell.execute_reply":"2023-04-04T05:50:38.209636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## helper","metadata":{}},{"cell_type":"code","source":"class AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","metadata":{"execution":{"iopub.status.busy":"2023-04-04T05:50:38.212989Z","iopub.execute_input":"2023-04-04T05:50:38.213481Z","iopub.status.idle":"2023-04-04T05:50:38.223704Z","shell.execute_reply.started":"2023-04-04T05:50:38.213439Z","shell.execute_reply":"2023-04-04T05:50:38.222663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def init_logger(log_file):\n    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=log_file)\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\ndef set_seed(seed=None, cudnn_deterministic=True):\n    if seed is None:\n        seed = 42\n\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = cudnn_deterministic\n    torch.backends.cudnn.benchmark = False","metadata":{"execution":{"iopub.status.busy":"2023-04-04T05:50:38.225626Z","iopub.execute_input":"2023-04-04T05:50:38.226059Z","iopub.status.idle":"2023-04-04T05:50:38.235593Z","shell.execute_reply.started":"2023-04-04T05:50:38.225965Z","shell.execute_reply":"2023-04-04T05:50:38.234144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_dirs(cfg):\n    for dir in [cfg.model_dir, cfg.figures_dir, cfg.submission_dir, cfg.log_dir]:\n        os.makedirs(dir, exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T05:50:38.241459Z","iopub.execute_input":"2023-04-04T05:50:38.241784Z","iopub.status.idle":"2023-04-04T05:50:38.247843Z","shell.execute_reply.started":"2023-04-04T05:50:38.241756Z","shell.execute_reply":"2023-04-04T05:50:38.246748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cfg_init(cfg, mode='train'):\n    set_seed(cfg.seed)\n    # set_env_name()\n    # set_dataset_path(cfg)\n\n    if mode == 'train':\n        make_dirs(cfg)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T05:50:38.249241Z","iopub.execute_input":"2023-04-04T05:50:38.24971Z","iopub.status.idle":"2023-04-04T05:50:38.257126Z","shell.execute_reply.started":"2023-04-04T05:50:38.249675Z","shell.execute_reply":"2023-04-04T05:50:38.255307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg_init(CFG)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nLogger = init_logger(log_file=CFG.log_path)\n\nLogger.info('\\n\\n-------- exp_info -----------------')\n# Logger.info(datetime.datetime.now().strftime('%Y年%m月%d日 %H:%M:%S'))","metadata":{"execution":{"iopub.status.busy":"2023-04-04T05:50:38.258387Z","iopub.execute_input":"2023-04-04T05:50:38.258747Z","iopub.status.idle":"2023-04-04T05:50:38.326583Z","shell.execute_reply.started":"2023-04-04T05:50:38.258711Z","shell.execute_reply":"2023-04-04T05:50:38.325136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## image, mask","metadata":{}},{"cell_type":"code","source":"def read_image_mask(fragment_id):\n\n    images = []\n\n    # idxs = range(65)\n    mid = 65 // 2\n    start = mid - CFG.in_chans // 2\n    end = mid + CFG.in_chans // 2\n    idxs = range(start, end)\n\n    for i in tqdm(idxs):\n        \n        image = cv2.imread(CFG.comp_dataset_path + f\"train/{fragment_id}/surface_volume/{i:02}.tif\", 0)\n\n        pad0 = (CFG.tile_size - image.shape[0] % CFG.tile_size)\n        pad1 = (CFG.tile_size - image.shape[1] % CFG.tile_size)\n\n        image = np.pad(image, [(0, pad0), (0, pad1)], constant_values=0)\n\n        images.append(image)\n    images = np.stack(images, axis=2)\n\n    mask = cv2.imread(CFG.comp_dataset_path + f\"train/{fragment_id}/inklabels.png\", 0)\n    mask = np.pad(mask, [(0, pad0), (0, pad1)], constant_values=0)\n\n    mask = mask.astype('float32')\n    mask /= 255.0\n    \n    return images, mask","metadata":{"execution":{"iopub.status.busy":"2023-04-04T05:50:38.328402Z","iopub.execute_input":"2023-04-04T05:50:38.329105Z","iopub.status.idle":"2023-04-04T05:50:38.33872Z","shell.execute_reply.started":"2023-04-04T05:50:38.329062Z","shell.execute_reply":"2023-04-04T05:50:38.337763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_train_valid_dataset():\n    train_images = []\n    train_masks = []\n\n    valid_images = []\n    valid_masks = []\n    valid_xyxys = []\n\n    for fragment_id in range(1, 4):\n\n        image, mask = read_image_mask(fragment_id)\n\n        x1_list = list(range(0, image.shape[1]-CFG.tile_size+1, CFG.stride))\n        y1_list = list(range(0, image.shape[0]-CFG.tile_size+1, CFG.stride))\n\n        for y1 in y1_list:\n            for x1 in x1_list:\n                y2 = y1 + CFG.tile_size\n                x2 = x1 + CFG.tile_size\n                # xyxys.append((x1, y1, x2, y2))\n        \n                if fragment_id == CFG.valid_id:\n                    valid_images.append(image[y1:y2, x1:x2])\n                    valid_masks.append(mask[y1:y2, x1:x2, None])\n\n                    valid_xyxys.append([x1, y1, x2, y2])\n                else:\n                    train_images.append(image[y1:y2, x1:x2])\n                    train_masks.append(mask[y1:y2, x1:x2, None])\n\n    return train_images, train_masks, valid_images, valid_masks, valid_xyxys","metadata":{"execution":{"iopub.status.busy":"2023-04-04T05:50:38.3407Z","iopub.execute_input":"2023-04-04T05:50:38.341555Z","iopub.status.idle":"2023-04-04T05:50:38.351622Z","shell.execute_reply.started":"2023-04-04T05:50:38.341513Z","shell.execute_reply":"2023-04-04T05:50:38.350835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images, train_masks, valid_images, valid_masks, valid_xyxys = get_train_valid_dataset()","metadata":{"execution":{"iopub.status.busy":"2023-04-04T05:50:38.353277Z","iopub.execute_input":"2023-04-04T05:50:38.354134Z","iopub.status.idle":"2023-04-04T05:51:20.631165Z","shell.execute_reply.started":"2023-04-04T05:50:38.354042Z","shell.execute_reply":"2023-04-04T05:51:20.630108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_xyxys = np.stack(valid_xyxys)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T05:51:20.632692Z","iopub.execute_input":"2023-04-04T05:51:20.63304Z","iopub.status.idle":"2023-04-04T05:51:20.64927Z","shell.execute_reply.started":"2023-04-04T05:51:20.632997Z","shell.execute_reply":"2023-04-04T05:51:20.647916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## dataset","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom torch.utils.data import DataLoader, Dataset\nimport cv2\nimport torch\nimport os\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import ImageOnlyTransform","metadata":{"execution":{"iopub.status.busy":"2023-04-04T05:51:20.651337Z","iopub.execute_input":"2023-04-04T05:51:20.651743Z","iopub.status.idle":"2023-04-04T05:51:20.658373Z","shell.execute_reply.started":"2023-04-04T05:51:20.651703Z","shell.execute_reply":"2023-04-04T05:51:20.656822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_transforms(data, cfg):\n    if data == 'train':\n        aug = A.Compose(cfg.train_aug_list)\n    elif data == 'valid':\n        aug = A.Compose(cfg.valid_aug_list)\n\n    # print(aug)\n    return aug\n\nclass CustomDataset(Dataset):\n    def __init__(self, images, cfg, labels=None, transform=None):\n        self.images = images\n        self.cfg = cfg\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        # return len(self.df)\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        image = self.images[idx]\n        label = self.labels[idx]\n\n        if self.transform:\n            data = self.transform(image=image, mask=label)\n            image = data['image']\n            label = data['mask']\n\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2023-04-04T05:51:20.660178Z","iopub.execute_input":"2023-04-04T05:51:20.661414Z","iopub.status.idle":"2023-04-04T05:51:20.670557Z","shell.execute_reply.started":"2023-04-04T05:51:20.66137Z","shell.execute_reply":"2023-04-04T05:51:20.669713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain_dataset = CustomDataset(\n    train_images, CFG, labels=train_masks, transform=get_transforms(data='train', cfg=CFG))\nvalid_dataset = CustomDataset(\n    valid_images, CFG, labels=valid_masks, transform=get_transforms(data='valid', cfg=CFG))\n\ntrain_loader = DataLoader(train_dataset,\n                          batch_size=CFG.train_batch_size,\n                          shuffle=True,\n                          num_workers=CFG.num_workers, pin_memory=True, drop_last=True,\n                          )\nvalid_loader = DataLoader(valid_dataset,\n                          batch_size=CFG.valid_batch_size,\n                          shuffle=False,\n                          num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-04T05:51:20.67192Z","iopub.execute_input":"2023-04-04T05:51:20.673078Z","iopub.status.idle":"2023-04-04T05:51:20.683545Z","shell.execute_reply.started":"2023-04-04T05:51:20.67304Z","shell.execute_reply":"2023-04-04T05:51:20.682452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset[0][0].shape","metadata":{"execution":{"iopub.status.busy":"2023-04-04T05:51:20.684968Z","iopub.execute_input":"2023-04-04T05:51:20.685727Z","iopub.status.idle":"2023-04-04T05:51:20.73428Z","shell.execute_reply.started":"2023-04-04T05:51:20.685689Z","shell.execute_reply":"2023-04-04T05:51:20.733329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nplot_dataset = CustomDataset(\n    train_images, CFG, labels=train_masks)\n\ntransform = CFG.train_aug_list\ntransform = A.Compose(\n    [t for t in transform if not isinstance(t, (A.Normalize, ToTensorV2))])\n\n\nplot_count = 0\nfor i in range(1000):\n\n    image, mask = plot_dataset[i]\n    data = transform(image=image, mask=mask)\n    aug_image = data['image']\n    aug_mask = data['mask']\n\n    if mask.sum() == 0:\n        continue\n\n    fig, axes = plt.subplots(1, 4, figsize=(15, 8))\n    axes[0].imshow(image[..., 0], cmap=\"gray\")\n    axes[1].imshow(mask, cmap=\"gray\")\n    axes[2].imshow(aug_image[..., 0], cmap=\"gray\")\n    axes[3].imshow(aug_mask, cmap=\"gray\")\n    \n    plt.savefig(CFG.figures_dir + f'aug_fold_{CFG.valid_id}_{plot_count}.png')\n\n    plot_count += 1\n    if plot_count == 5:\n        break","metadata":{"execution":{"iopub.status.busy":"2023-04-04T05:51:20.735684Z","iopub.execute_input":"2023-04-04T05:51:20.736127Z","iopub.status.idle":"2023-04-04T05:51:26.656584Z","shell.execute_reply.started":"2023-04-04T05:51:20.736089Z","shell.execute_reply":"2023-04-04T05:51:26.655392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del plot_dataset\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-04-04T05:51:26.658231Z","iopub.execute_input":"2023-04-04T05:51:26.658688Z","iopub.status.idle":"2023-04-04T05:51:26.872679Z","shell.execute_reply.started":"2023-04-04T05:51:26.65865Z","shell.execute_reply":"2023-04-04T05:51:26.871379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## model","metadata":{}},{"cell_type":"code","source":"class CustomModel(nn.Module):\n    def __init__(self, cfg, weight=None):\n        super().__init__()\n        self.cfg = cfg\n\n        self.encoder = smp.Unet(\n            encoder_name=cfg.backbone, \n            encoder_weights=weight,\n            in_channels=cfg.in_chans,\n            classes=cfg.target_size,\n            activation=None,\n        )\n\n    def forward(self, image):\n        output = self.encoder(image)\n        # output = output.squeeze(-1)\n        return output\n\n\ndef build_model(cfg, weight=\"imagenet\"):\n    print('model_name', cfg.model_name)\n    print('backbone', cfg.backbone)\n\n    model = CustomModel(cfg, weight)\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-04-04T05:51:26.875667Z","iopub.execute_input":"2023-04-04T05:51:26.876524Z","iopub.status.idle":"2023-04-04T05:51:26.88457Z","shell.execute_reply.started":"2023-04-04T05:51:26.876478Z","shell.execute_reply":"2023-04-04T05:51:26.88351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## scheduler","metadata":{}},{"cell_type":"code","source":"\nimport torch.nn as nn\nimport torch\nimport math\nimport time\nimport numpy as np\nimport torch\n\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\nfrom warmup_scheduler import GradualWarmupScheduler\n\n\nclass GradualWarmupSchedulerV2(GradualWarmupScheduler):\n    \"\"\"\n    https://www.kaggle.com/code/underwearfitting/single-fold-training-of-resnet200d-lb0-965\n    \"\"\"\n    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n        super(GradualWarmupSchedulerV2, self).__init__(\n            optimizer, multiplier, total_epoch, after_scheduler)\n\n    def get_lr(self):\n        if self.last_epoch > self.total_epoch:\n            if self.after_scheduler:\n                if not self.finished:\n                    self.after_scheduler.base_lrs = [\n                        base_lr * self.multiplier for base_lr in self.base_lrs]\n                    self.finished = True\n                return self.after_scheduler.get_lr()\n            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n        if self.multiplier == 1.0:\n            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n        else:\n            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]\n\ndef get_scheduler(cfg, optimizer):\n    scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(\n        optimizer, cfg.epochs, eta_min=1e-7)\n    scheduler = GradualWarmupSchedulerV2(\n        optimizer, multiplier=10, total_epoch=1, after_scheduler=scheduler_cosine)\n\n    return scheduler\n\ndef scheduler_step(scheduler, avg_val_loss, epoch):\n    scheduler.step(epoch)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-04T05:51:26.886749Z","iopub.execute_input":"2023-04-04T05:51:26.88703Z","iopub.status.idle":"2023-04-04T05:51:26.901457Z","shell.execute_reply.started":"2023-04-04T05:51:26.887004Z","shell.execute_reply":"2023-04-04T05:51:26.900426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_model(CFG)\nmodel.to(device)\n\noptimizer = AdamW(model.parameters(), lr=CFG.lr)\nscheduler = get_scheduler(CFG, optimizer)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T05:51:26.902941Z","iopub.execute_input":"2023-04-04T05:51:26.903907Z","iopub.status.idle":"2023-04-04T05:51:30.20362Z","shell.execute_reply.started":"2023-04-04T05:51:26.903869Z","shell.execute_reply":"2023-04-04T05:51:30.202562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## loss","metadata":{}},{"cell_type":"code","source":"\nDiceLoss = smp.losses.DiceLoss(mode='binary')\nBCELoss = smp.losses.SoftBCEWithLogitsLoss()\n\nalpha = 0.5\nbeta = 1 - alpha\nTverskyLoss = smp.losses.TverskyLoss(\n    mode='binary', log_loss=False, alpha=alpha, beta=beta)\n\ndef criterion(y_pred, y_true):\n    # return 0.5 * BCELoss(y_pred, y_true) + 0.5 * DiceLoss(y_pred, y_true)\n    return BCELoss(y_pred, y_true)\n    # return 0.5 * BCELoss(y_pred, y_true) + 0.5 * TverskyLoss(y_pred, y_true)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T05:51:30.205266Z","iopub.execute_input":"2023-04-04T05:51:30.205674Z","iopub.status.idle":"2023-04-04T05:51:30.214065Z","shell.execute_reply.started":"2023-04-04T05:51:30.205636Z","shell.execute_reply":"2023-04-04T05:51:30.212997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## train, val","metadata":{}},{"cell_type":"code","source":"def train_fn(train_loader, model, criterion, optimizer, device):\n    model.train()\n\n    scaler = GradScaler(enabled=CFG.use_amp)\n    losses = AverageMeter()\n\n    for step, (images, labels) in tqdm(enumerate(train_loader), total=len(train_loader)):\n        images = images.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n\n        with autocast(CFG.use_amp):\n            y_preds = model(images)\n            loss = criterion(y_preds, labels)\n\n        losses.update(loss.item(), batch_size)\n        scaler.scale(loss).backward()\n\n        grad_norm = torch.nn.utils.clip_grad_norm_(\n            model.parameters(), CFG.max_grad_norm)\n\n        scaler.step(optimizer)\n        scaler.update()\n        optimizer.zero_grad()\n\n    return losses.avg\n\ndef valid_fn(valid_loader, model, criterion, device, valid_xyxys, valid_mask_gt):\n    mask_pred = np.zeros(valid_mask_gt.shape)\n    mask_count = np.zeros(valid_mask_gt.shape)\n\n    model.eval()\n    losses = AverageMeter()\n\n    for step, (images, labels) in tqdm(enumerate(valid_loader), total=len(valid_loader)):\n        images = images.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n\n        with torch.no_grad():\n            y_preds = model(images)\n            loss = criterion(y_preds, labels)\n        losses.update(loss.item(), batch_size)\n\n        # make whole mask\n        y_preds = torch.sigmoid(y_preds).to('cpu').numpy()\n        start_idx = step*CFG.valid_batch_size\n        end_idx = start_idx + batch_size\n        for i, (x1, y1, x2, y2) in enumerate(valid_xyxys[start_idx:end_idx]):\n            mask_pred[y1:y2, x1:x2] += y_preds[i].squeeze(0)\n            mask_count[y1:y2, x1:x2] += np.ones((CFG.tile_size, CFG.tile_size))\n\n    print(f'mask_count_min: {mask_count.min()}')\n    mask_pred /= mask_count\n    return losses.avg, mask_pred","metadata":{"execution":{"iopub.status.busy":"2023-04-04T05:51:30.21568Z","iopub.execute_input":"2023-04-04T05:51:30.216151Z","iopub.status.idle":"2023-04-04T05:51:30.23155Z","shell.execute_reply.started":"2023-04-04T05:51:30.21611Z","shell.execute_reply":"2023-04-04T05:51:30.230509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## metrics","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import fbeta_score\n\ndef fbeta_numpy(targets, preds, beta=0.5, smooth=1e-5):\n    \"\"\"\n    https://www.kaggle.com/competitions/vesuvius-challenge-ink-detection/discussion/397288\n    \"\"\"\n    y_true_count = targets.sum()\n    ctp = preds[targets==1].sum()\n    cfp = preds[targets==0].sum()\n    beta_squared = beta * beta\n\n    c_precision = ctp / (ctp + cfp + smooth)\n    c_recall = ctp / (y_true_count + smooth)\n    dice = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall + smooth)\n\n    return dice\n\ndef calc_fbeta(mask, mask_pred):\n    mask = mask.astype(int).flatten()\n    mask_pred = mask_pred.flatten()\n\n    best_th = 0\n    best_dice = 0\n    for th in np.array(range(10, 50+1, 5)) / 100:\n        \n        # dice = fbeta_score(mask, (mask_pred >= th).astype(int), beta=0.5)\n        dice = fbeta_numpy(mask, (mask_pred >= th).astype(int), beta=0.5)\n        print(f'th: {th}, fbeta: {dice}')\n\n        if dice > best_dice:\n            best_dice = dice\n            best_th = th\n    \n    Logger.info(f'best_th: {best_th}, fbeta: {best_dice}')\n    return best_dice, best_th\n\n\ndef calc_cv(mask_gt, mask_pred):\n    best_dice, best_th = calc_fbeta(mask_gt, mask_pred)\n\n    return best_dice, best_th","metadata":{"execution":{"iopub.status.busy":"2023-04-04T05:51:30.237696Z","iopub.execute_input":"2023-04-04T05:51:30.23806Z","iopub.status.idle":"2023-04-04T05:51:30.248748Z","shell.execute_reply.started":"2023-04-04T05:51:30.23803Z","shell.execute_reply":"2023-04-04T05:51:30.247706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## main","metadata":{}},{"cell_type":"code","source":"fragment_id = CFG.valid_id\n\nvalid_mask_gt = cv2.imread(CFG.comp_dataset_path + f\"train/{fragment_id}/inklabels.png\", 0)\nvalid_mask_gt = valid_mask_gt / 255\npad0 = (CFG.tile_size - valid_mask_gt.shape[0] % CFG.tile_size)\npad1 = (CFG.tile_size - valid_mask_gt.shape[1] % CFG.tile_size)\nvalid_mask_gt = np.pad(valid_mask_gt, [(0, pad0), (0, pad1)], constant_values=0)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T05:51:30.250303Z","iopub.execute_input":"2023-04-04T05:51:30.250925Z","iopub.status.idle":"2023-04-04T05:51:30.765669Z","shell.execute_reply.started":"2023-04-04T05:51:30.250887Z","shell.execute_reply":"2023-04-04T05:51:30.764621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfold = CFG.valid_id\n\nif CFG.metric_direction == 'minimize':\n    best_score = np.inf\nelif CFG.metric_direction == 'maximize':\n    best_score = -1\n\nbest_loss = np.inf\n\nfor epoch in range(CFG.epochs):\n\n    start_time = time.time()\n\n    # train\n    avg_loss = train_fn(train_loader, model, criterion, optimizer, device)\n\n    # eval\n    avg_val_loss, mask_pred = valid_fn(\n        valid_loader, model, criterion, device, valid_xyxys, valid_mask_gt)\n\n    scheduler_step(scheduler, avg_val_loss, epoch)\n\n    best_dice, best_th = calc_cv(valid_mask_gt, mask_pred)\n\n    # score = avg_val_loss\n    score = best_dice\n\n    elapsed = time.time() - start_time\n\n    Logger.info(\n        f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n    # Logger.info(f'Epoch {epoch+1} - avgScore: {avg_score:.4f}')\n    Logger.info(\n        f'Epoch {epoch+1} - avgScore: {score:.4f}')\n\n    if CFG.metric_direction == 'minimize':\n        update_best = score < best_score\n    elif CFG.metric_direction == 'maximize':\n        update_best = score > best_score\n\n    if update_best:\n        best_loss = avg_val_loss\n        best_score = score\n\n        Logger.info(\n            f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n        Logger.info(\n            f'Epoch {epoch+1} - Save Best Loss: {best_loss:.4f} Model')\n        \n        torch.save({'model': model.state_dict(),\n                    'preds': mask_pred},\n                    CFG.model_dir + f'{CFG.model_name}_fold{fold}_best.pth')","metadata":{"execution":{"iopub.status.busy":"2023-04-04T05:51:30.767438Z","iopub.execute_input":"2023-04-04T05:51:30.767837Z","iopub.status.idle":"2023-04-04T06:51:14.117016Z","shell.execute_reply.started":"2023-04-04T05:51:30.767795Z","shell.execute_reply":"2023-04-04T06:51:14.115452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"check_point = torch.load(\n    CFG.model_dir + f'{CFG.model_name}_fold{fold}_{CFG.inf_weight}.pth', map_location=torch.device('cpu'))","metadata":{"execution":{"iopub.status.busy":"2023-04-04T06:51:14.122159Z","iopub.execute_input":"2023-04-04T06:51:14.122575Z","iopub.status.idle":"2023-04-04T06:51:17.552043Z","shell.execute_reply.started":"2023-04-04T06:51:14.122524Z","shell.execute_reply":"2023-04-04T06:51:17.550364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask_pred = check_point['preds']","metadata":{"execution":{"iopub.status.busy":"2023-04-04T06:51:17.553755Z","iopub.execute_input":"2023-04-04T06:51:17.554159Z","iopub.status.idle":"2023-04-04T06:51:17.591872Z","shell.execute_reply.started":"2023-04-04T06:51:17.554119Z","shell.execute_reply":"2023-04-04T06:51:17.590665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_dice, best_th  = calc_fbeta(valid_mask_gt, mask_pred)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T06:51:17.593945Z","iopub.execute_input":"2023-04-04T06:51:17.594773Z","iopub.status.idle":"2023-04-04T06:51:23.216932Z","shell.execute_reply.started":"2023-04-04T06:51:17.594736Z","shell.execute_reply":"2023-04-04T06:51:23.215813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 3, figsize=(15, 8))\naxes[0].imshow(valid_mask_gt)\naxes[1].imshow(mask_pred)\naxes[2].imshow((mask_pred>=best_th).astype(int))","metadata":{"execution":{"iopub.status.busy":"2023-04-04T06:51:23.218597Z","iopub.execute_input":"2023-04-04T06:51:23.218989Z","iopub.status.idle":"2023-04-04T06:51:37.221509Z","shell.execute_reply.started":"2023-04-04T06:51:23.21895Z","shell.execute_reply":"2023-04-04T06:51:37.220561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(mask_pred.flatten(), bins=20)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T06:51:37.22286Z","iopub.execute_input":"2023-04-04T06:51:37.223885Z","iopub.status.idle":"2023-04-04T06:51:38.516812Z","shell.execute_reply.started":"2023-04-04T06:51:37.223843Z","shell.execute_reply":"2023-04-04T06:51:38.515375Z"},"trusted":true},"execution_count":null,"outputs":[]}]}