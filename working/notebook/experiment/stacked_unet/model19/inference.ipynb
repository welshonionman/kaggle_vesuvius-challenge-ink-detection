{"cells":[{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["import sys\n","is_kaggle_notebook = \"kaggle_web_client\" in sys.modules\n","if is_kaggle_notebook:\n","    !pip uninstall timm -y"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T04:51:15.411176Z","iopub.status.busy":"2023-04-04T04:51:15.41084Z","iopub.status.idle":"2023-04-04T04:51:20.141027Z","shell.execute_reply":"2023-04-04T04:51:20.13956Z","shell.execute_reply.started":"2023-04-04T04:51:15.411146Z"},"trusted":true},"outputs":[],"source":["sys.path.append('/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4')\n","sys.path.append('/kaggle/input/efficientnet-pytorch/EfficientNet-PyTorch-master')\n","sys.path.append('/kaggle/input/timm-pytorch-image-models/pytorch-image-models-master')\n","sys.path.append('/kaggle/input/segmentation-models-pytorch/segmentation_models.pytorch-master')\n","sys.path.append('/kaggle/input/einops/einops-master')\n"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["import gc\n","import os\n","import random\n","import shutil\n","import sys\n","import warnings\n","from glob import glob\n","import re\n","\n","import albumentations as A\n","import cv2\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from albumentations.pytorch import ToTensorV2\n","from einops import rearrange\n","from segmentation_models_pytorch.decoders.unet.decoder import DecoderBlock\n","from timm.models.resnet import resnet14t, resnet34d\n","from torch.utils.data import DataLoader, Dataset\n","from tqdm import tqdm\n","from scipy.ndimage import gaussian_filter\n","from scipy import ndimage\n","\n","warnings.simplefilter(\"ignore\")\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","is_kaggle_notebook = \"kaggle_web_client\" in sys.modules"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## config"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T04:51:23.625553Z","iopub.status.busy":"2023-04-04T04:51:23.62525Z","iopub.status.idle":"2023-04-04T04:51:23.638088Z","shell.execute_reply":"2023-04-04T04:51:23.636525Z","shell.execute_reply.started":"2023-04-04T04:51:23.625523Z"},"trusted":true},"outputs":[],"source":["class CFG:\n","\n","    # ============== comp exp name =============\n","    comp_name = 'vesuvius'\n","    comp_dir_path = '/kaggle/input/'\n","    comp_folder_name = 'vesuvius-challenge-ink-detection'\n","\n","    start = 23\n","    stop = 38\n","    input_dirs = f\"/kaggle/input/vesuvius-challenge-ink-detection/test/\"\n","    stack_dir = f\"/kaggle/working/dataset_inference/\"\n","    save_dir = f\"/kaggle/working/dataset_inference/nonflatten/\"\n","    test_dataset_path = f\"/kaggle/working/dataset_inference/nonflatten/{start}-{stop}/\"\n","\n","    exp_name = \"model19\"\n","    TH = 0.45\n","    fold = 5\n","\n","\n","    # ============== model cfg =============\n","    in_chans = stop-start+1\n","    crop_depth = 6\n","    random_shift = 1\n","    layer_shift = [0, 2, 4, 6, 8]\n","    # ============== pred target =============\n","    \n","    target_size = 1\n","    TTA = is_kaggle_notebook\n","    \n","    # ============== training cfg =============\n","    size = 256\n","    tile_size = 256\n","    stride = tile_size // 4\n","\n","    valid_batch_size = 8  # 32\n","    use_amp = True\n","\n","    # ============== fixed =============\n","    num_workers = 4\n","\n","    # ============== augmentation =============\n","    valid_aug_list = [\n","        A.Resize(size, size),\n","        A.Normalize(\n","            mean=[0] * in_chans,\n","            std=[1] * in_chans,\n","            max_pixel_value=65535,\n","        ),\n","        ToTensorV2(transpose_mask=True),\n","    ]\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## dataset preprocess"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["GAUSSIAN_BLUR_TOPOGRAPHIC_MAP = False\n","\n","\n","def split_label_mask_inference(input_dir, dataset_dir, fragment_i):\n","    shutil.copy(f\"{input_dir}/mask.png\", dataset_dir + f\"mask_{fragment_i}.png\")\n","\n","\n","def split_stack_image(input_dir, dataset_dir, split=1):\n","    fragment_i = input_dir.split(\"/\")[-1]\n","    image_height = cv2.imread(f\"{input_dir}/surface_volume/01.tif\", -1).shape[0]\n","    split_height = image_height // split\n","\n","    for split_i in range(split):\n","        image_stack = None\n","        images = []\n","\n","        surfaces_path = sorted(glob(f\"{input_dir}/surface_volume/*.tif\"))\n","        save_npy_path = dataset_dir + f\"image_stack_{fragment_i}_{split_i}.npy\"\n","        if os.path.exists(save_npy_path):\n","            continue\n","\n","        for surface_path in tqdm(surfaces_path):\n","            image = cv2.imread(surface_path, -1)\n","            if split_i < split - 1:\n","                image = image[split_i * split_height: (split_i + 1) * split_height, :]\n","            else:\n","                image = image[split_i * split_height: image_height, :]\n","            images.append(image)\n","            del image\n","        image_stack = np.stack(images)\n","\n","        with open(save_npy_path, \"wb\") as f:\n","            np.save(f, image_stack, allow_pickle=True)\n","\n","\n","def extract_nonflatten_layers(input_stack_path, output_stack_path, start, stop):\n","    if os.path.exists(output_stack_path):\n","        return\n","\n","    stack = np.load(open(input_stack_path, \"rb\"))\n","    stack = stack[start: stop + 1, :, :]\n","\n","    with open(output_stack_path, \"wb\") as f:\n","        np.save(f, stack, allow_pickle=True)\n","\n","\n","def concat_npy(save_dir, fragment_i):\n","    output_path = f\"{save_dir}/{fragment_i}.npy\"\n","    if os.path.exists(output_path):\n","        return\n","\n","    npy_list = []\n","    for npy in sorted(glob(f\"{save_dir}/{fragment_i}_*.npy\")):\n","        npy_list.append(np.load(open(npy, 'rb')))\n","\n","    result = np.concatenate(npy_list, axis=1)\n","\n","    with open(output_path, 'wb') as f:\n","        np.save(f, result, allow_pickle=True)\n"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["if is_kaggle_notebook:\n","    split=3\n","else:\n","    split=1\n"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/vesuvius-challenge-ink-detection/test/a\n","/kaggle/input/vesuvius-challenge-ink-detection/test/b\n"]}],"source":["for input_dir in glob(f\"{CFG.input_dirs}/*\"):\n","    print(input_dir)\n","    image_stack_dir = f\"{CFG.stack_dir}/nonflatten/\"\n","    extract_save_dir = f\"{image_stack_dir}/{CFG.start}-{CFG.stop}/\"\n","    fragment_i = input_dir.split(\"/\")[-1]\n","    \n","    os.makedirs(CFG.stack_dir, exist_ok=True)\n","    os.makedirs(image_stack_dir, exist_ok=True)\n","    os.makedirs(extract_save_dir, exist_ok=True)\n","\n","    split_label_mask_inference(input_dir, CFG.stack_dir, fragment_i)\n","    split_stack_image(input_dir, CFG.stack_dir, split)\n","\n","    for split_i in range(split):\n","        input_stack_path = f\"{CFG.stack_dir}/image_stack_{fragment_i}_{split_i}.npy\"\n","        output_stack_path = f\"{extract_save_dir}/{fragment_i}_{split_i}.npy\"\n","        extract_nonflatten_layers(input_stack_path, output_stack_path, CFG.start, CFG.stop)\n","\n","    concat_npy(extract_save_dir, fragment_i)\n","    \n","    "]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["def create_topomap(image_stack, x, y, range, z_buffer):\n","    clipped_stack = image_stack[:, x: x + range, y: y + range]\n","    clipped_stack = clipped_stack / 65535\n","    clipped_stack = np.flip(clipped_stack, axis=0)\n","    gauss_stack = gaussian_filter(clipped_stack, sigma=1)\n","    gauss_stack = ndimage.sobel(gauss_stack, axis=0)\n","    gauss_stack = gaussian_filter(gauss_stack, sigma=1)\n","\n","    filtered_stack = np.where(gauss_stack >= 0.5, 1, 0)  # type: ignore\n","    topographic_map = np.argmax(filtered_stack, axis=0)\n","\n","    topographic_map = 64 - np.where(topographic_map == 0, 64, topographic_map).astype(\"uint8\")\n","    topographic_map = cv2.medianBlur(topographic_map, 15)\n","\n","    is_idx = np.indices(clipped_stack.shape)\n","    flattened_stack = clipped_stack[(is_idx[0] + topographic_map - z_buffer) % clipped_stack.shape[0], is_idx[1], is_idx[2], ]\n","    flattened_stack = (np.flip(flattened_stack, axis=0) * 65536).astype(\"uint16\")\n","\n","    return topographic_map\n","\n","\n","def create_whole_topomap(image_stack_path, output_topography_path):\n","    if os.path.exists(output_topography_path):\n","        return\n","    \n","    image_stack = np.load(open(image_stack_path, \"rb\"))\n","\n","    _, image_stack_x, image_stack_y = image_stack.shape\n","    output_topography = np.zeros(image_stack.shape[1:])\n","    for x in range(0, image_stack_x, 250):\n","        for y in range(0, image_stack_y, 250):\n","            topographic_map = create_topomap(image_stack, x, y, 250, 5)\n","            output_topography[x: x + 250, y: y + 250] = topographic_map\n","\n","    cv2.imwrite(output_topography_path, output_topography)\n","\n","def concat_topo(save_dir, fragment_i):\n","    topo_list = []\n","    for topo in sorted(glob(f\"{save_dir}/topography_{fragment_i}_*.png\")):\n","        topo_list.append(cv2.imread(topo, -1))\n","    result = np.concatenate(topo_list, axis=0)\n","    output_topo_fname = f\"{save_dir}/topography_{fragment_i}.png\"\n","    print(output_topo_fname)\n","    cv2.imwrite(output_topo_fname, result)"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/working/dataset_inference//topography_a.png\n","/kaggle/working/dataset_inference//topography_b.png\n"]}],"source":["for image_stack_path in glob(f\"{CFG.stack_dir}/image_stack*\"):\n","    fragment_i = image_stack_path.split(\"/\")[-1].split(\"_\")[2]\n","    split_i = image_stack_path.split(\"/\")[-1].split(\"_\")[3].split(\".\")[0]\n","    output_topography_path = os.path.join(CFG.stack_dir + f\"topography_{fragment_i}_{split_i}.png\")\n","    create_whole_topomap(image_stack_path, output_topography_path)\n","\n","\n","fragment_list = [i.split(\"_\")[-1].split(\".\")[0] for i in glob(f\"{CFG.stack_dir}/mask*\")]\n","\n","for fragment_i in fragment_list:\n","    concat_topo(CFG.stack_dir , fragment_i)\n","    topography = cv2.imread(f\"{CFG.stack_dir}/topography_{fragment_i}.png\", 0)\n","    new_mask=np.logical_and(45>topography, topography>20).astype(\"uint8\")*255\n","    cv2.imwrite(f\"{CFG.stack_dir}/mask_{fragment_i}.png\", new_mask)"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["if is_kaggle_notebook:\n","    for path in glob(f\"{CFG.stack_dir}/**/*.*\", recursive=True):\n","        if re.search(r\"_\\d\", path):\n","            os.remove(path)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## helper"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T04:51:23.813569Z","iopub.status.busy":"2023-04-04T04:51:23.813141Z","iopub.status.idle":"2023-04-04T04:51:23.824293Z","shell.execute_reply":"2023-04-04T04:51:23.823167Z","shell.execute_reply.started":"2023-04-04T04:51:23.813471Z"},"trusted":true},"outputs":[],"source":["# ref.: https://www.kaggle.com/stainsby/fast-tested-rle\n","def rle(img):\n","    '''\n","    img: numpy array, 1 - mask, 0 - background\n","    Returns run length as string formated\n","    '''\n","    pixels = img.flatten()\n","    # pixels = (pixels >= thr).astype(int)\n","\n","    pixels = np.concatenate([[0], pixels, [0]])\n","    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n","    runs[1::2] -= runs[::2]\n","    return ' '.join(str(x) for x in runs)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## dataset"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["def preprocess(image):\n","    return image\n"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T04:51:23.826492Z","iopub.status.busy":"2023-04-04T04:51:23.826048Z","iopub.status.idle":"2023-04-04T04:51:23.835717Z","shell.execute_reply":"2023-04-04T04:51:23.834666Z","shell.execute_reply.started":"2023-04-04T04:51:23.826453Z"},"trusted":true},"outputs":[],"source":["def read_image(fragment_id):\n","    image_stack = np.load(open(f\"{CFG.test_dataset_path}/{fragment_id}.npy\", 'rb'))\n","\n","    pad0 = (CFG.tile_size - image_stack.shape[1] % CFG.tile_size)\n","    pad1 = (CFG.tile_size - image_stack.shape[2] % CFG.tile_size)\n","\n","    image_stack = np.pad(image_stack, [(0, 0), (0, pad0), (0, pad1)], constant_values=0)\n","    image_stack = image_stack.transpose((1, 2, 0))\n","    image_stack = preprocess(image_stack)\n","\n","    return image_stack\n","\n","def get_transforms(data, cfg):\n","    aug = A.Compose(cfg.valid_aug_list)\n","\n","    # print(aug)\n","    return aug\n","\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, images, cfg, labels=None, transform=None):\n","        self.images = images\n","        self.cfg = cfg\n","        self.labels = labels\n","        self.transform = transform\n","\n","    def __len__(self):\n","        # return len(self.xyxys)\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        # x1, y1, x2, y2 = self.xyxys[idx]\n","        image = self.images[idx]\n","        data = self.transform(image=image)\n","        image = data['image']\n","        return image\n","\n","def make_test_dataset(fragment_id):\n","    test_images = read_image(fragment_id)\n","    x1_list = list(range(0, test_images.shape[1]-CFG.tile_size+1, CFG.stride))\n","    y1_list = list(range(0, test_images.shape[0]-CFG.tile_size+1, CFG.stride))\n","\n","    test_images_list = []\n","    xyxys = []\n","    for y1 in y1_list:\n","        for x1 in x1_list:\n","            y2 = y1 + CFG.tile_size\n","            x2 = x1 + CFG.tile_size\n","\n","            test_images_list.append(test_images[y1:y2, x1:x2])\n","            xyxys.append((x1, y1, x2, y2))\n","    # xyxys = np.stack(xyxys)\n","\n","    test_dataset = CustomDataset(test_images_list, CFG, transform=get_transforms(data='valid', cfg=CFG))\n","\n","    test_loader = DataLoader(test_dataset,\n","                             batch_size=CFG.valid_batch_size,\n","                             shuffle=False,\n","                             num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","    # return test_images_list\n","    return test_loader, xyxys\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## model"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T04:51:23.865123Z","iopub.status.busy":"2023-04-04T04:51:23.864743Z","iopub.status.idle":"2023-04-04T04:51:23.87814Z","shell.execute_reply":"2023-04-04T04:51:23.877181Z","shell.execute_reply.started":"2023-04-04T04:51:23.86506Z"},"trusted":true},"outputs":[],"source":["class SmpUnetDecoder(nn.Module):\n","    def __init__(self,\n","                 in_channel,\n","                 skip_channel,\n","                 out_channel,\n","                 ):\n","        super().__init__()\n","        self.center = nn.Identity()\n","\n","        i_channel = [in_channel,] + out_channel[:-1]\n","        s_channel = skip_channel\n","        o_channel = out_channel\n","        block = [\n","            DecoderBlock(i, s, o, use_batchnorm=True, attention_type=None)\n","            for i, s, o in zip(i_channel, s_channel, o_channel)\n","        ]\n","        self.block = nn.ModuleList(block)\n","\n","    def forward(self, feature, skip):\n","        d = self.center(feature)\n","        decode = []\n","        for i, block in enumerate(self.block):\n","            s = skip[i]\n","            d = block(d, s)\n","            decode.append(d)\n","\n","        last = d\n","        return last, decode\n","\n","\n","class Net(nn.Module):\n","    def __init__(self,):\n","        super().__init__()\n","        self.output_type = ['inference', 'loss']\n","\n","        conv_dim = 64\n","        encoder1_dim = [conv_dim, 64, 128, 256, 512, ]\n","        decoder1_dim = [256, 128, 64, 64,]\n","\n","        self.encoder1 = resnet34d(pretrained=True, in_chans=CFG.crop_depth)\n","\n","        self.decoder1 = SmpUnetDecoder(\n","            in_channel=encoder1_dim[-1],\n","            skip_channel=encoder1_dim[:-1][::-1],\n","            out_channel=decoder1_dim,\n","        )\n","        # -- pool attention weight\n","        self.weight1 = nn.ModuleList([\n","            nn.Sequential(\n","                nn.Conv2d(dim, dim, kernel_size=3, padding=1),\n","                nn.ReLU(inplace=True),\n","            ) for dim in encoder1_dim\n","        ])\n","        self.logit1 = nn.Conv2d(decoder1_dim[-1], 1, kernel_size=1)\n","\n","        # --------------------------------\n","        #\n","        encoder2_dim = [256, 512, 1024, 2048]\n","        decoder2_dim = [512, 256, 128, ]\n","        self.encoder2 = resnet14t(pretrained=True, in_chans=decoder1_dim[-1])\n","\n","        self.decoder2 = SmpUnetDecoder(\n","            in_channel=encoder2_dim[-1],\n","            skip_channel=encoder2_dim[:-1][::-1],\n","            out_channel=decoder2_dim,\n","        )\n","        self.logit2 = nn.Conv2d(decoder2_dim[-1], 1, kernel_size=1)\n","\n","    def forward(self, batch):\n","        v = batch\n","        B, C, H, W = v.shape\n","        random_shift = random.randint(0, CFG.random_shift)\n","        vv = [\n","            v[:, i+random_shift:i+random_shift+CFG.crop_depth] for i in CFG.layer_shift\n","        ]\n","        K = len(vv)\n","        x = torch.cat(vv, 0)\n","        # x = v\n","\n","        # ----------------------\n","        encoder = []\n","        e = self.encoder1\n","        x = e.conv1(x)\n","        x = e.bn1(x)\n","        x = e.act1(x)\n","        encoder.append(x)\n","        x = F.avg_pool2d(x, kernel_size=2, stride=2)\n","        x = e.layer1(x)\n","        encoder.append(x)\n","        x = e.layer2(x)\n","        encoder.append(x)\n","        x = e.layer3(x)\n","        encoder.append(x)\n","        x = e.layer4(x)\n","        encoder.append(x)\n","        # print('encoder', [f.shape for f in encoder])\n","\n","        for i in range(len(encoder)):\n","            e = encoder[i]\n","            f = self.weight1[i](e)\n","            _, c, h, w = e.shape\n","            f = rearrange(f, '(K B) c h w -> B K c h w', K=K, B=B, h=h, w=w)  #\n","            e = rearrange(e, '(K B) c h w -> B K c h w', K=K, B=B, h=h, w=w)  #\n","            w = F.softmax(f, 1)\n","            e = (w * e).sum(1)\n","            encoder[i] = e\n","\n","        feature = encoder[-1]\n","        skip = encoder[:-1][::-1]\n","        last, decoder = self.decoder1(feature, skip)\n","        logit1 = self.logit1(last)\n","\n","        # ----------------------\n","        x = last  # .detach()\n","        # x = F.avg_pool2d(x,kernel_size=2,stride=2)\n","        encoder = []\n","        e = self.encoder2\n","        x = e.layer1(x)\n","        encoder.append(x)\n","        x = e.layer2(x)\n","        encoder.append(x)\n","        x = e.layer3(x)\n","        encoder.append(x)\n","        x = e.layer4(x)\n","        encoder.append(x)\n","\n","        feature = encoder[-1]\n","        skip = encoder[:-1][::-1]\n","        last, decoder = self.decoder2(feature, skip)\n","        logit2 = self.logit2(last)\n","        logit1 = F.interpolate(logit1, size=(H, W), mode='bilinear', align_corners=False, antialias=True)\n","        logit2 = F.interpolate(logit2, size=(H, W), mode='bilinear', align_corners=False, antialias=True)\n","\n","        return logit1, logit2\n"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["def TTA(x: torch.Tensor, model: nn.Module):\n","    if CFG.TTA:\n","        shape = x.shape\n","        x = [x, *[torch.rot90(x, k=i, dims=(-2, -1)) for i in range(1, 4)]]\n","        x = torch.cat(x, dim=0)\n","        x = model(x)\n","        x = torch.sigmoid(x)\n","        x = x.reshape(4, shape[0], *shape[2:])\n","        x = [torch.rot90(x[i], k=-i, dims=(-2, -1)) for i in range(4)]\n","        x = torch.stack(x, dim=0)\n","        return x.mean(0)\n","    else:\n","        x = model(x)\n","        x = torch.sigmoid(x)\n","        return x\n"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["class EnsembleModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.model = nn.ModuleList()\n","        for fold in range(CFG.fold):\n","            _model = Net()\n","\n","            if os.path.exists(f'{CFG.comp_dir_path}/{CFG.exp_name}/{CFG.exp_name}_fold{fold}.pth'):\n","                model_path = f'{CFG.comp_dir_path}/{CFG.exp_name}/{CFG.exp_name}_fold{fold}.pth'\n","            else:\n","                model_path = f'./{CFG.exp_name}/{CFG.exp_name}_fold{fold}.pth'\n","            print(model_path)\n","            state = torch.load(model_path)['model']\n","            _model.load_state_dict(state)\n","            _model.eval()\n","\n","            self.model.append(_model)\n","    \n","    def forward(self,x):\n","        output=[]\n","        for m in self.model:\n","            output.append(m(x)[0])\n","        output=torch.stack(output,dim=0).mean(0)\n","        return output"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T04:51:23.892968Z","iopub.status.busy":"2023-04-04T04:51:23.892497Z","iopub.status.idle":"2023-04-04T04:51:23.908Z","shell.execute_reply":"2023-04-04T04:51:23.906772Z","shell.execute_reply.started":"2023-04-04T04:51:23.892927Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["./model19/model19_fold0.pth\n","./model19/model19_fold1.pth\n","./model19/model19_fold2.pth\n","./model19/model19_fold3.pth\n","./model19/model19_fold4.pth\n"]}],"source":["num_gpus = torch.cuda.device_count()\n","device_ids = list(range(num_gpus))\n","\n","fragment_ids = sorted(os.listdir(CFG.input_dirs))\n","model = EnsembleModel()\n","model = nn.DataParallel(model, device_ids=device_ids)\n","model = model.cuda()\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## main"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  2%|‚ñè         | 8/498 [00:04<04:51,  1.68it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[35], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m batch_size \u001b[39m=\u001b[39m images\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> 25\u001b[0m     y_preds \u001b[39m=\u001b[39m TTA(images,model)\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     27\u001b[0m start_idx \u001b[39m=\u001b[39m step\u001b[39m*\u001b[39mCFG\u001b[39m.\u001b[39mvalid_batch_size\n\u001b[1;32m     28\u001b[0m end_idx \u001b[39m=\u001b[39m start_idx \u001b[39m+\u001b[39m batch_size\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["results = []\n","for fragment_id in fragment_ids:\n","\n","    test_loader, xyxys = make_test_dataset(fragment_id)\n","\n","    binary_mask = cv2.imread(CFG.stack_dir + f\"/mask_{fragment_id}.png\", 0)\n","    binary_mask = (binary_mask / 255).astype(int)\n","\n","    ori_h = binary_mask.shape[0]\n","    ori_w = binary_mask.shape[1]\n","\n","    pad0 = (CFG.tile_size - binary_mask.shape[0] % CFG.tile_size)\n","    pad1 = (CFG.tile_size - binary_mask.shape[1] % CFG.tile_size)\n","\n","    binary_mask = np.pad(binary_mask, [(0, pad0), (0, pad1)], constant_values=0)\n","\n","    mask_pred = np.zeros(binary_mask.shape)\n","    mask_count = np.zeros(binary_mask.shape)\n","\n","    for step, (images) in tqdm(enumerate(test_loader), total=len(test_loader)):\n","        images = images.cuda()\n","        batch_size = images.size(0)\n","\n","        with torch.no_grad():\n","            y_preds = TTA(images,model).cpu().numpy()\n","\n","        start_idx = step*CFG.valid_batch_size\n","        end_idx = start_idx + batch_size\n","        for i, (x1, y1, x2, y2) in enumerate(xyxys[start_idx:end_idx]):\n","            mask_pred[y1:y2, x1:x2] += y_preds[i].reshape(mask_pred[y1:y2, x1:x2].shape)\n","            mask_count[y1:y2, x1:x2] += np.ones((CFG.tile_size, CFG.tile_size))\n","\n","    mask_pred /= mask_count\n","    del test_loader\n","\n","    mask_pred = mask_pred[:ori_h, :ori_w]\n","    binary_mask = binary_mask[:ori_h, :ori_w]\n","\n","    mask_pred *= binary_mask\n","    mask_pred_thresh = (mask_pred >= CFG.TH).astype(int)\n","    \n","    plt.figure(figsize=(10,10))\n","    plt.imshow(mask_pred)\n","    plt.show()\n","    plt.figure(figsize=(10,10))\n","    plt.imshow(mask_pred_thresh)\n","    plt.show()\n","\n","    inklabels_rle = rle(mask_pred_thresh)\n","\n","    results.append((fragment_id, inklabels_rle))\n","\n","\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","    break"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## submission"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T05:04:59.79253Z","iopub.status.busy":"2023-04-04T05:04:59.791024Z","iopub.status.idle":"2023-04-04T05:04:59.80219Z","shell.execute_reply":"2023-04-04T05:04:59.801265Z","shell.execute_reply.started":"2023-04-04T05:04:59.792484Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>Predicted</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>a</td>\n","      <td>625222 6 631549 13 631568 12 637875 38 644197 ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>b</td>\n","      <td>1282 190 1736 56 1797 8 1808 71 7611 192 8064 ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Id                                          Predicted\n","0  a  625222 6 631549 13 631568 12 637875 38 644197 ...\n","1  b  1282 190 1736 56 1797 8 1808 71 7611 192 8064 ..."]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["sub = pd.DataFrame(results, columns=['Id', 'Predicted'])\n","sample_sub = pd.read_csv(\"/kaggle/input/vesuvius-challenge-ink-detection/sample_submission.csv\")\n","sample_sub = pd.merge(sample_sub[['Id']], sub, on='Id', how='left')\n","if is_kaggle_notebook:\n","    sample_sub.to_csv(\"submission.csv\", index=False)\n","sample_sub\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":4}
