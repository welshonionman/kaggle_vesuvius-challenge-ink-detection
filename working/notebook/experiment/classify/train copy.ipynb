{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install segmentation_models_pytorch warmup_scheduler albumentations -q\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import os\n","import sys\n","import random\n","from glob import glob\n","import warnings\n","import timm\n","\n","import torch\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","sys.path.append('/kaggle/working/notebook/experiment/2d')\n","from script.helper import *\n","from script.dataset import *\n","from script.metrics import *\n","from script.trainer import *\n","from script.model import *\n","from script.loss import *\n","from script.scheduler import *\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## config"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T05:50:38.19323Z","iopub.status.busy":"2023-04-04T05:50:38.192696Z","iopub.status.idle":"2023-04-04T05:50:38.211206Z","shell.execute_reply":"2023-04-04T05:50:38.209636Z","shell.execute_reply.started":"2023-04-04T05:50:38.193193Z"},"trusted":true},"outputs":[],"source":["class CFG:\n","    # ============== comp exp name =============\n","    comp_name = 'vesuvius'\n","    comp_dir_path = '/kaggle/input/'\n","    comp_folder_name = 'vesuvius-challenge-ink-detection'\n","\n","    dataset_path = \"/kaggle/working/dataset_train/\"\n","    train_dataset_path = \"/kaggle/working/dataset_train/nonflatten/29-34/\"\n","\n","    exp_name = os.getcwd().split('/')[-1]\n","\n","    # ============== model cfg =============\n","    model_name = 'Unet'\n","    backbone = 'se_resnext50_32x4d'\n","    in_chans = 6\n","\n","    # ============== pred target =============\n","    target_size = 1\n","\n","    # ============== training cfg =============\n","    size = 16\n","    tile_size = 16\n","    stride = tile_size //1\n","\n","    train_batch_size = 64  # 32\n","    valid_batch_size = train_batch_size * 2\n","    use_amp = True\n","\n","    scheduler = 'GradualWarmupSchedulerV2'\n","    # scheduler = 'CosineAnnealingLR'\n","\n","    epochs = 20  # 15\n","\n","    warmup_factor = 10\n","    lr = 1e-4 / warmup_factor\n","\n","    # ============== fold =============\n","    metric_direction = 'maximize'  # maximize, 'minimize'\n","\n","    # ============== fixed =============\n","    pretrained = True\n","    inf_weight = 'best'  # 'best'\n","\n","    min_lr = 1e-6\n","    weight_decay = 1e-6\n","    max_grad_norm = 1000\n","\n","    print_freq = 50\n","    num_workers = 4\n","\n","    seed = 42\n","\n","    # ============== augmentation =============\n","    train_aug_list = [\n","        A.Resize(size, size),\n","        A.HorizontalFlip(p=0.5),\n","        A.VerticalFlip(p=0.5),\n","        # A.RandomBrightnessContrast(p=0.75),\n","        # A.ShiftScaleRotate(p=0.75),\n","        # A.OneOf([\n","        #         A.GaussNoise(var_limit=[10, 50]),\n","        #         A.GaussianBlur(),\n","        #         A.MotionBlur(),\n","        #         ], p=0.4),\n","        # A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.5),\n","        # A.CoarseDropout(max_holes=1, max_width=int(size * 0.3), max_height=int(size * 0.3),\n","        #                 mask_fill_value=0, p=0.5),\n","        A.Normalize(\n","            mean=[0] * in_chans,\n","            std=[1] * in_chans,\n","            max_pixel_value=65535,\n","        ),\n","        ToTensorV2(transpose_mask=True),\n","    ]\n","\n","    valid_aug_list = [\n","        A.Resize(size, size),\n","        A.Normalize(\n","            mean=[0] * in_chans,\n","            std=[1] * in_chans,\n","            max_pixel_value=65535,\n","        ),\n","        ToTensorV2(transpose_mask=True),\n","    ]\n","\n","\n","warnings.filterwarnings(\"ignore\")\n","torch.backends.cudnn.benchmark = True  # type: ignore\n","\n","set_seed(CFG.seed)\n","os.makedirs(f'./{CFG.exp_name}/', exist_ok=True)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Dataset"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def preprocess(image, fragment_i, split_i):\n","    # image=np.clip(image, a_min=0.15,a_max=0.7)\n","    return image\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def get_train_valid_dataset(valid_fragment_i, valid_split_i, cfg, preprocess, label_prefix=\"inklabels\"):\n","    train_images = []\n","    train_labels = []\n","    train_masks = []\n","\n","    valid_images = []\n","    valid_labels = []\n","    valid_xyxys = []\n","\n","    for stack_path in glob(f\"{cfg.train_dataset_path}/*\"):\n","        fragment_i = int(stack_path.split(\".\")[-2].split(\"/\")[-1].split(\"_\")[0])\n","        split_i = int(stack_path.split(\".\")[-2].split(\"/\")[-1].split(\"_\")[1])\n","        image, label, mask = read_image_label_mask(stack_path, cfg, preprocess, fragment_i, split_i, label_prefix)\n","        x1_list = list(range(0, image.shape[1]-cfg.tile_size+1, cfg.stride))\n","        y1_list = list(range(0, image.shape[0]-cfg.tile_size+1, cfg.stride))\n","\n","        for y1 in y1_list:\n","            for x1 in x1_list:\n","                y2 = y1 + cfg.tile_size\n","                x2 = x1 + cfg.tile_size\n","\n","                if (fragment_i == valid_fragment_i) & (split_i == valid_split_i):\n","                    valid_images.append(image[y1:y2, x1:x2])\n","                    label_ = np.where(np.any(np.array(label[y1:y2, x1:x2, None]) == 1), 1, 0)\n","                    valid_labels.append(label_)\n","\n","                    valid_xyxys.append([x1, y1, x2, y2])\n","                else:\n","                    train_images.append(image[y1:y2, x1:x2])\n","                    label_ = np.where(np.any(np.array(label[y1:y2, x1:x2, None]) == 1), 1, 0)\n","                    train_labels.append(label_)\n","                    train_masks.append(mask[y1:y2, x1:x2, None])\n","    valid_xyxys = np.stack(valid_xyxys)\n","    return train_images, train_labels, train_masks, valid_images, valid_labels, valid_xyxys"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","len(train_images) = 708764\n","train_images[0].shape = (16, 16, 6)\n","train_labels[0].shape = ()\n","train_masks[0].shape = (16, 16, 1)\n","\n","len(valid_images) = 202752\n","valid_images[0].shape = (16, 16, 6)\n","valid_labels[0].shape = ()\n","\n"]}],"source":["# confirmation\n","\n","valid_fragment_i = 1\n","valid_split_i = 0\n","\n","train_images, train_labels, train_masks, valid_images, valid_labels, valid_xyxys = get_train_valid_dataset(valid_fragment_i, valid_split_i, CFG, preprocess)\n","\n","print(f\"\"\"\n","{len(train_images) = }\n","{train_images[0].shape = }\n","{train_labels[0].shape = }\n","{train_masks[0].shape = }\n","\n","{len(valid_images) = }\n","{valid_images[0].shape = }\n","{valid_labels[0].shape = }\n","\"\"\")\n","\n","# id = random.randint(0, len(train_labels))\n","# visualize_train_images(id, train_images, train_labels, train_masks)\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, images, cfg, labels=None, transform=None):\n","        self.images = images\n","        self.cfg = cfg\n","        self.labels = labels\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        image = self.images[idx]\n","        label = self.labels[idx]  # type: ignore\n","\n","        if self.transform:\n","            data = self.transform(image=image)\n","            image = data['image']\n","        label=torch.tensor(label).unsqueeze(0).float()\n","        return image, label"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["train_dataset = CustomDataset(\n","    train_images, CFG, labels=train_labels, transform=get_transforms(data='train', cfg=CFG))\n","\n","valid_dataset = CustomDataset(\n","    valid_images, CFG, labels=valid_labels, transform=get_transforms(data='valid', cfg=CFG))\n","\n","train_loader = DataLoader(train_dataset,\n","                            batch_size=CFG.train_batch_size,\n","                            shuffle=True,\n","                            num_workers=CFG.num_workers, pin_memory=True, drop_last=True,\n","                            )\n","valid_loader = DataLoader(valid_dataset,\n","                            batch_size=CFG.valid_batch_size,\n","                            shuffle=False,\n","                            num_workers=CFG.num_workers, pin_memory=True, drop_last=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## main"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["from timm.utils import AverageMeter\n","from tqdm import tqdm\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import confusion_matrix\n","\n","model = timm.create_model(\"efficientnet_b0\", pretrained=True, num_classes=1, in_chans=CFG.in_chans,).cuda()\n","\n","# 最適化手法\n","optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-4)\n","\n","# 損失関数\n","criterion = torch.nn.BCEWithLogitsLoss()\n","\n","# ログ記録用の変数\n","history = {\"train\": [], \"test\": []}\n","scaler = torch.cuda.amp.GradScaler()"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Epoch: 0\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 11074/11074 [03:59<00:00, 46.21it/s]\n","100%|██████████| 1584/1584 [00:10<00:00, 156.95it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[[178335    194]\n"," [ 24219      4]]\n","\n","Epoch: 1\n"]},{"name":"stderr","output_type":"stream","text":["  3%|▎         | 315/11074 [00:06<03:58, 45.17it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m     loss \u001b[39m=\u001b[39m criterion(preds, label)\n\u001b[1;32m     18\u001b[0m     scaler\u001b[39m.\u001b[39mscale(loss)\u001b[39m.\u001b[39mbackward()  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     scaler\u001b[39m.\u001b[39;49mstep(optimizer)\n\u001b[1;32m     20\u001b[0m     scaler\u001b[39m.\u001b[39mupdate()\n\u001b[1;32m     21\u001b[0m train_loss\u001b[39m.\u001b[39mupdate(val \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem(), n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(image))\n","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:370\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    368\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(optimizer_state[\u001b[39m\"\u001b[39m\u001b[39mfound_inf_per_device\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 370\u001b[0m retval \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_opt_step(optimizer, optimizer_state, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    372\u001b[0m optimizer_state[\u001b[39m\"\u001b[39m\u001b[39mstage\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m OptState\u001b[39m.\u001b[39mSTEPPED\n\u001b[1;32m    374\u001b[0m \u001b[39mreturn\u001b[39;00m retval\n","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:290\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    288\u001b[0m retval \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39msum\u001b[39m(v\u001b[39m.\u001b[39mitem() \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m optimizer_state[\u001b[39m\"\u001b[39m\u001b[39mfound_inf_per_device\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mvalues()):\n\u001b[0;32m--> 290\u001b[0m     retval \u001b[39m=\u001b[39m optimizer\u001b[39m.\u001b[39;49mstep(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    291\u001b[0m \u001b[39mreturn\u001b[39;00m retval\n","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py:171\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    158\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m\"\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    160\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[1;32m    161\u001b[0m         group,\n\u001b[1;32m    162\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    168\u001b[0m         state_steps,\n\u001b[1;32m    169\u001b[0m     )\n\u001b[0;32m--> 171\u001b[0m     adamw(\n\u001b[1;32m    172\u001b[0m         params_with_grad,\n\u001b[1;32m    173\u001b[0m         grads,\n\u001b[1;32m    174\u001b[0m         exp_avgs,\n\u001b[1;32m    175\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    176\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    177\u001b[0m         state_steps,\n\u001b[1;32m    178\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    179\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    180\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    181\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    182\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    183\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    184\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    185\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    186\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    187\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    188\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    189\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    190\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    191\u001b[0m     )\n\u001b[1;32m    193\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py:321\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 321\u001b[0m func(\n\u001b[1;32m    322\u001b[0m     params,\n\u001b[1;32m    323\u001b[0m     grads,\n\u001b[1;32m    324\u001b[0m     exp_avgs,\n\u001b[1;32m    325\u001b[0m     exp_avg_sqs,\n\u001b[1;32m    326\u001b[0m     max_exp_avg_sqs,\n\u001b[1;32m    327\u001b[0m     state_steps,\n\u001b[1;32m    328\u001b[0m     amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    329\u001b[0m     beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    330\u001b[0m     beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    331\u001b[0m     lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    332\u001b[0m     weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    333\u001b[0m     eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    334\u001b[0m     maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    335\u001b[0m     capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    336\u001b[0m     differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    337\u001b[0m     grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    338\u001b[0m     found_inf\u001b[39m=\u001b[39;49mfound_inf,\n\u001b[1;32m    339\u001b[0m )\n","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py:548\u001b[0m, in \u001b[0;36m_multi_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    546\u001b[0m     torch\u001b[39m.\u001b[39m_foreach_addcdiv_(device_params, device_exp_avgs, denom)\n\u001b[1;32m    547\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 548\u001b[0m     bias_correction1 \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta1 \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m _get_value(step) \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m device_state_steps]\n\u001b[1;32m    549\u001b[0m     bias_correction2 \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta2 \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m _get_value(step) \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m device_state_steps]\n\u001b[1;32m    551\u001b[0m     step_size \u001b[39m=\u001b[39m _stack_if_compiling([(lr \u001b[39m/\u001b[39m bc) \u001b[39m*\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39mfor\u001b[39;00m bc \u001b[39min\u001b[39;00m bias_correction1])\n","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py:548\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    546\u001b[0m     torch\u001b[39m.\u001b[39m_foreach_addcdiv_(device_params, device_exp_avgs, denom)\n\u001b[1;32m    547\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 548\u001b[0m     bias_correction1 \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta1 \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m _get_value(step) \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m device_state_steps]\n\u001b[1;32m    549\u001b[0m     bias_correction2 \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta2 \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m _get_value(step) \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m device_state_steps]\n\u001b[1;32m    551\u001b[0m     step_size \u001b[39m=\u001b[39m _stack_if_compiling([(lr \u001b[39m/\u001b[39m bc) \u001b[39m*\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39mfor\u001b[39;00m bc \u001b[39min\u001b[39;00m bias_correction1])\n","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py:44\u001b[0m, in \u001b[0;36m_get_value\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n\u001b[1;32m     43\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m     \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39;49mitem()\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# 学習回数\n","for epoch in range(5):\n","    preds_list=[]\n","    target_list=[]\n","    print(\"\\nEpoch:\", epoch)\n","\n","    # 学習\n","    model.train()\n","    train_loss = AverageMeter()\n","    for batch in tqdm(train_loader):\n","        optimizer.zero_grad()\n","        image = batch[0].cuda() #(batch_size, channel, size, size)\n","        label = batch[1].cuda() #(batch_size)\n","        \n","        with torch.cuda.amp.autocast():  # type: ignore\n","            preds = model(image)\n","            loss = criterion(preds, label)\n","            scaler.scale(loss).backward()  # type: ignore\n","            scaler.step(optimizer)\n","            scaler.update()\n","        train_loss.update(val = loss.item(), n = len(image))\n","\n","    # 検証\n","    model.eval()\n","    test_loss = AverageMeter()\n","    with torch.no_grad():\n","        for batch in tqdm(valid_loader):\n","            image = batch[0].cuda() #(batch_size, channel, size, size)\n","            label = batch[1].cuda() #(batch_size)\n","            preds = model(image) #(batch_size, num_class)\n","            loss = criterion(preds, label)\n","            # print(label)\n","            test_loss.update(val = loss.item(), n = len(image))\n","            preds=preds.squeeze(-1).cpu().sigmoid().numpy()\n","            \n","            preds_prob=np.where(preds>0.5, 1, 0).tolist()\n","            preds_list+=preds_prob\n","            \n","            flat_list = [item for sublist in label.cpu().numpy().tolist() for item in sublist]\n","            target_list+=flat_list\n","            # print(accuracy_score(preds_list, target_list))\n","    matrix = confusion_matrix(target_list, preds_list)\n","    print(matrix)\n","\n","    # 誤差出力\n","    # print(train_loss.avg)\n","    # print(test_loss.avg)\n","    history[\"train\"].append(train_loss.avg)\n","    history[\"test\"].append(test_loss.avg)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[]\n"]}],"source":["print(matrix)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["array([], shape=(0, 0), dtype=int64)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":4}
