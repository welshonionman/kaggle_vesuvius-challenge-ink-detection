{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/Kaggle/kaggle-api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir(\"/kaggle/\")\n",
    "!bash /kaggle/vscode_extentions.sh\n",
    "!pip install -r ./requirements.txt -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "# def init():\n",
    "os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
    "shutil.copy(\"/kaggle/kaggle.json\", \"/root/.kaggle\")\n",
    "!chmod 600 / root/.kaggle/kaggle.json\n",
    "\n",
    "\n",
    "def date():\n",
    "    day = datetime.today().day\n",
    "    month = datetime.today().month\n",
    "    date = f\"{month:02}{day:02}\"\n",
    "    return date\n",
    "\n",
    "\n",
    "def download_comp_datasets(comp_name):\n",
    "    !kaggle competitions download {comp_name} --path /kaggle/input/{comp_name}/\n",
    "    shutil.unpack_archive(f'/kaggle/input/{comp_name}/{comp_name}.zip', f'/kaggle/input/{comp_name}/')\n",
    "    os.remove(f'/kaggle/input/{comp_name}/{comp_name}.zip')\n",
    "\n",
    "\n",
    "def download_datasets(dataset):\n",
    "    savedir = dataset.split(\"/\")[-1]\n",
    "    !kaggle datasets download {dataset} --unzip --quiet --path /kaggle/input/{savedir}\n",
    "\n",
    "\n",
    "def create_datasets(folder):\n",
    "    title=folder.rstrip(\"/\").split(\"/\")[-1]\n",
    "    print(title)\n",
    "    with open(\"/kaggle/dataset-metadata.json\", \"r\") as js:\n",
    "        dict_json = json.load(js)\n",
    "    dict_json[\"title\"] = title\n",
    "    dict_json[\"id\"] = f\"welshonionman/{title}\"\n",
    "    with open(f\"{folder}/dataset-metadata.json\", \"w\") as js:\n",
    "        json.dump(dict_json, js, indent=4)\n",
    "            \n",
    "    !kaggle datasets create -p {folder} --quiet\n",
    "    # os.remove(f\"{folder}/dataset-metadata.json\")\n",
    "\n",
    "\n",
    "def pull_kernel(kernel, path=\"./\"):\n",
    "    fname = kernel.rstrip(\"/\").split(\"/\")[-1]\n",
    "    !kaggle kernels pull {kernel} --path ./tmp\n",
    "    shutil.move(f\"./tmp/{fname}.ipynb\", f\"/kaggle/working/notebook/reference/{fname}.ipynb\")\n",
    "\n",
    "def push_kernel(path, datasets=[], comp=\"\"):\n",
    "    shutil.copy(path,\"/tmp/tmp.ipynb\")\n",
    "    fname = Path(path)\n",
    "    rand=random.randint(1000,9999)\n",
    "    with open(\"/kaggle/kernel-metadata.json\", \"r\") as js:\n",
    "        dict_json = json.load(js)\n",
    "    dict_json[\"id\"] = f\"welshonionman/{fname.stem}{rand}\"\n",
    "    dict_json[\"title\"] = f\"{fname.stem}{rand}\"\n",
    "    dict_json[\"code_file\"] = str(fname)\n",
    "    dict_json[\"competition_sources\"] = comp\n",
    "    dict_json[\"enable_gpu\"]= \"true\"\n",
    "    dict_json[\"dataset_sources\"] = datasets\n",
    "    dict_json[\"language\"] = \"python\"\n",
    "    dict_json[\"kernel_type\"] = \"notebook\"\n",
    "\n",
    "    with open(\"/kernel-metadata.json\", \"w\") as js:\n",
    "        json.dump(dict_json, js, indent=4)\n",
    "    !kaggle kernels push\n",
    "    os.remove(f\"/kernel-metadata.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vesuvius-challenge-ink-detection.zip to /kaggle/input/vesuvius-challenge-ink-detection\n",
      "100%|█████████████████████████████████████▉| 20.6G/20.6G [21:22<00:00, 16.8MB/s]\n",
      "100%|██████████████████████████████████████| 20.6G/20.6G [21:22<00:00, 17.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "download_comp_datasets(\"vesuvius-challenge-ink-detection\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_datasets(\"brettolsen/updated-fragment-masks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source code downloaded to ./tmp/lb0-68-one-fold-stacked-unet.ipynb\n"
     ]
    }
   ],
   "source": [
    "pull_kernel(\"hengck23/lb0-68-one-fold-stacked-unet/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model17\n",
      "Your private Dataset is being created. Please check progress at https://www.kaggle.com/datasets/welshonionman/model17\n",
      "model18\n",
      "Your private Dataset is being created. Please check progress at https://www.kaggle.com/datasets/welshonionman/model18\n"
     ]
    }
   ],
   "source": [
    "create_datasets(\"/kaggle/working/notebook/experiment/stacked_unet/model17/model17\")\n",
    "create_datasets(\"/kaggle/working/notebook/experiment/stacked_unet/model18/model18\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel version 1 successfully pushed.  Please check progress at https://www.kaggle.com/code/welshonionman/inference4960\n"
     ]
    }
   ],
   "source": [
    "# push_kernel(\"/kaggle/kaggle-api.ipynb\", datasets=[\"welshonionman/vesuvius-models\"], comp=[\"vesuvius-challenge-ink-detection\"])\n",
    "datasets = [\"salmanahmedtamu/efficientnet-pytorch\",\n",
    "            \"rishabhiitbhu/pretrainedmodels\",\n",
    "            \"salmanahmedtamu/segmentation-models-pytorch\",\n",
    "            \"kozodoi/timm-pytorch-image-models\",\n",
    "            \"tanakar/vesuvius-models-public\",\n",
    "            \"edomingo/einops\",\n",
    "\n",
    "            \"welshonionman/model3\",\n",
    "            \"welshonionman/model13\",\n",
    "            \"welshonionman/model14\",\n",
    "            \"welshonionman/model15\",\n",
    "            \"welshonionman/model16\",\n",
    "            \"welshonionman/model17\",\n",
    "            \"welshonionman/model18\",\n",
    "            \"welshonionman/model19\",\n",
    "            ]\n",
    "\n",
    "push_kernel(\"/kaggle/working/notebook/submit/inference.ipynb\", datasets=datasets, comp=[\"vesuvius-challenge-ink-detection\"]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
