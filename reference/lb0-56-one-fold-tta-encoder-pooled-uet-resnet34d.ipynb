{"cells":[{"cell_type":"markdown","metadata":{},"source":["notebook for discussion at:  \n","https://www.kaggle.com/competitions/vesuvius-challenge-ink-detection/discussion/407972"]},{"cell_type":"code","execution_count":15,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-05-14T05:30:30.605048Z","iopub.status.busy":"2023-05-14T05:30:30.604431Z","iopub.status.idle":"2023-05-14T05:30:38.61218Z","shell.execute_reply":"2023-05-14T05:30:38.610755Z","shell.execute_reply.started":"2023-05-14T05:30:30.605014Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["import ok !!!\n"]}],"source":["my_lib_dir ='/kaggle/input/ink-00/my_lib'\n","\n","import sys\n","sys.path.append(my_lib_dir)\n","sys.path.append('/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4')\n","sys.path.append('/kaggle/input/efficientnet-pytorch/EfficientNet-PyTorch-master')\n","sys.path.append('/kaggle/input/timm-pytorch-image-models/pytorch-image-models-master')\n","sys.path.append('/kaggle/input/segmentation-models-pytorch/segmentation_models.pytorch-master')\n","sys.path.append('/kaggle/input/einops/einops-master')\n","\n","# from helper import *\n","\n","import numpy as np\n","import pandas as pd\n","\n","from collections import defaultdict\n","from glob import glob\n","import PIL.Image as Image\n","Image.MAX_IMAGE_PIXELS = 10000000000  # Ignore PIL warnings about large images\n","\n","import cv2\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from einops import rearrange, reduce, repeat\n","import segmentation_models_pytorch as smp\n","from segmentation_models_pytorch.decoders.unet.decoder import UnetDecoder\n","from timm.models.resnet import *\n","\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","#matplotlib.use('TkAgg')\n","%matplotlib inline \n","  \n","print('import ok !!!')"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T05:30:38.6147Z","iopub.status.busy":"2023-05-14T05:30:38.614351Z","iopub.status.idle":"2023-05-14T05:30:38.621572Z","shell.execute_reply":"2023-05-14T05:30:38.620373Z","shell.execute_reply.started":"2023-05-14T05:30:38.614669Z"},"trusted":true},"outputs":[],"source":["class Config(object):\n","\tmode = [\n","\t\t'train', #'test', 'train'\n","\t]\n","\tcrop_size  = 224\n","\tcrop_depth = 8+4\n","\tone_depth  = 8  #6+4\n","\n","CFG = Config()\n","CFG.fragment_z0 = 65//2-5-2 #-1\n","CFG.fragment_z1 = CFG.fragment_z0+CFG.crop_depth #+2\n","CFG.is_tta = True\n","\n","if 'train' in CFG.mode:\n","\tCFG.stride = CFG.crop_size//4\n","if 'test' in CFG.mode:\n","\tCFG.stride = CFG.crop_size//8\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["{'fragment_z0': 25, 'fragment_z1': 37, 'is_tta': True, 'stride': 56}"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["CFG.__dict__"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["from box import Box"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T05:30:38.627801Z","iopub.status.busy":"2023-05-14T05:30:38.627252Z","iopub.status.idle":"2023-05-14T05:30:38.649668Z","shell.execute_reply":"2023-05-14T05:30:38.648645Z","shell.execute_reply.started":"2023-05-14T05:30:38.627767Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["data_dir /kaggle/input/vesuvius-challenge-ink-detection/train\n","valid_id ['2a']\n","data ok !!!\n"]}],"source":["## dataset ##\n","if 'train' in CFG.mode:\n","\tdata_dir = '/kaggle/input/vesuvius-challenge-ink-detection/train'\n","\tvalid_id =[\n","\t    '2a',\n","\t]\n","\n","if 'test' in CFG.mode: \n","\tdata_dir = '/kaggle/input/vesuvius-challenge-ink-detection/test'\n","\n","\tvalid_id = glob(f'{data_dir}/*')\n","\tvalid_id = sorted(valid_id)\n","\tvalid_id = [f.split('/')[-1] for f in valid_id]\n","\n","print('data_dir', data_dir)\n","print('valid_id', valid_id)\n","\n","\n","\n","def do_binarise(m, threshold=0.5):\n","    m = m-m.min()\n","    m = m/(m.max()+1e-7)\n","    m = (m>threshold).astype(np.float32)\n","    return m\n","\n","def read_data(fragment_id, z0=CFG.fragment_z0, z1=CFG.fragment_z1):\n","    volume = []\n","    # start_timer = timer()\n","    for i in range(z0,z1):\n","        v = np.array(Image.open(f'{data_dir}/{fragment_id}/surface_volume/{i:02d}.tif'), dtype=np.uint16)\n","        v = (v >> 8).astype(np.uint8)\n","        volume.append(v)\n","        # print(f'\\r @ read_data(): volume{fragment_id}  {time_to_str(timer() - start_timer, \"sec\")}', end='', flush=True)\n","    volume = np.stack(volume, -1)\n","    height, width, depth = volume.shape\n","\n","    #---\n","    mask = cv2.imread(f'{data_dir}/{fragment_id}/mask.png',cv2.IMREAD_GRAYSCALE)\n","    mask = do_binarise(mask)\n","\n","    if 'train' in CFG.mode:\n","        ir    = cv2.imread(f'{data_dir}/{fragment_id}/ir.png',cv2.IMREAD_GRAYSCALE)\n","        label = cv2.imread(f'{data_dir}/{fragment_id}/inklabels.png',cv2.IMREAD_GRAYSCALE)\n","        ir    = ir/255\n","        label = do_binarise(label)\n","\n","    if 'test' in CFG.mode:\n","        ir = None\n","        label = None\n","\n","    d = dict(\n","        fragment_id = fragment_id,\n","        volume = volume,\n","        ir     = ir,\n","        label  = label,\n","        mask   = mask,\n","    )\n","    d=Box\n","    return d\n","\n","def read_data1(fragment_id):\n","\tif fragment_id=='2a':\n","\t\td = read_data('2')\n","\t\ty = { #ab split\n","\t\t\t'1': 4560,\n","\t\t\t'2': 9456,\n","\t\t\t'3': 4060,\n","\t\t}['2']\n","\t\td = Box(dict(\n","\t\t\tfragment_id='2a',\n","\t\t\tvolume  = d.volume[:y],\n","\t\t\tir      = d.ir[:y],\n","\t\t\tlabel   = d.label[:y],\n","\t\t\tmask    = d.mask[:y],))\n","\telse:\n","\t\td = read_data(fragment_id)\n","\treturn d\n","\n","def run_check_data():\n","    d=read_data1(valid_id[0])#valid_id[0]\n","    print('')\n","    print('fragment_id:', d.fragment_id)\n","    print('volume:', d.volume.shape, d.volume.min(), d.volume.max())\n","    print('mask  :', d.mask.shape, d.mask.min(), d.mask.max())\n","    if 'train' in CFG.mode:\n","        print('ir    :', d.ir.shape, d.ir.min(), d.ir.max())\n","        print('label :', d.label.shape, d.label.min(), d.label.max())\n","\n","#run_check_data()\n","print('data ok !!!')"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T05:30:38.65184Z","iopub.status.busy":"2023-05-14T05:30:38.651174Z","iopub.status.idle":"2023-05-14T05:30:40.232471Z","shell.execute_reply":"2023-05-14T05:30:40.231359Z","shell.execute_reply.started":"2023-05-14T05:30:38.651764Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["batch\n","                          volume : torch.Size([2, 12, 224, 224]) \n","output\n","                             ink : torch.Size([2, 1, 224, 224]) \n","net ok !!!\n"]}],"source":["## model ##\n","\n","\n","class SmpUnetDecoder(UnetDecoder):\n","\tdef __init__(self, **kwargs):\n","\t\tsuper(SmpUnetDecoder, self).__init__(\n","\t\t\t**kwargs)\n","\n","\tdef forward(self, encoder):\n","\t\tfeature = encoder[::-1]  # reverse channels to start from head of encoder\n","\t\thead = feature[0]\n","\t\tskip = feature[1:] + [None]\n","\t\td = self.center(head)\n","\n","\t\tdecoder = []\n","\t\tfor i, decoder_block in enumerate(self.blocks):\n","\t\t\t# print(i, d.shape, skip[i].shape if skip[i] is not None else 'none')\n","\t\t\t# print(decoder_block.conv1[0])\n","\t\t\t# print('')\n","\t\t\ts = skip[i]\n","\t\t\td = decoder_block(d, s)\n","\t\t\tdecoder.append(d)\n","\n","\t\tlast  = d\n","\t\treturn last, decoder\n","\n","class Net(nn.Module):\n","\tdef __init__(self,):\n","\t\tsuper().__init__()\n","\n","\t\tconv_dim=64\n","\t\tencoder_dim  = [conv_dim] + [64, 128, 256, 512 ]\n","\t\tself.encoder = resnet34d(pretrained=False,in_chans=CFG.one_depth)\n","\n","\t\tself.decoder = SmpUnetDecoder(\n","\t\t\tencoder_channels=[0] + encoder_dim,\n","\t\t\tdecoder_channels=[256, 128, 64, 32, 16],\n","\t\t\tn_blocks=5,\n","\t\t\tuse_batchnorm=True,\n","\t\t\tcenter=False,\n","\t\t\tattention_type=None,\n","\t\t)\n","\t\tself.logit = nn.Conv2d(16,1,kernel_size=1)\n","\n","\t\t#-- pool attention weight\n","\t\tself.weight = nn.ModuleList([\n","\t\t\tnn.Sequential(\n","\t\t\t\tnn.Conv2d(dim, dim, kernel_size=3, padding=1),\n","\t\t\t\tnn.ReLU(inplace=True),\n","\t\t\t) for dim in encoder_dim\n","\t\t])\n","\n","\tdef forward(self, batch):\n","\t\tv = batch['volume']\n","\t\tB,C,H,W = v.shape\n","\t\tvv = [\n","\t\t\tv[:, i:i+CFG.one_depth] for i in [0,2,4]\n","\t\t]\n","\t\tK = len(vv)\n","\t\tx = torch.cat(vv,0)\n","\t\t#x = v\n","\n","\t\t# ----\n","\t\tencoder = []\n","\t\tx = self.encoder.conv1(x)\n","\t\tx = self.encoder.bn1(x)\n","\t\tx = self.encoder.act1(x)   ; encoder.append(x)\n","\t\tx = F.avg_pool2d(x,kernel_size=2,stride=2)\n","\t\tx = self.encoder.layer1(x) ; encoder.append(x)\n","\t\tx = self.encoder.layer2(x) ; encoder.append(x)\n","\t\tx = self.encoder.layer3(x) ; encoder.append(x)\n","\t\tx = self.encoder.layer4(x) ; encoder.append(x)\n","\t\t#print('encoder', [f.shape for f in encoder])\n","\n","\t\t#encode pooling -------\n","\t\t#<todo> add positional encode (z slice no.)\n","\t\tfor i in range(len(encoder)):\n","\t\t\te = encoder[i]\n","\t\t\tf = self.weight[i](encoder[i])\n","\t\t\t_, c, h, w = f.shape\n","\t\t\tf = rearrange(f, '(K B) c h w -> B K c h w', K=K, B=B, h=h, w=w) #f.reshape(B, K, c, h, w)\n","\t\t\te = rearrange(e, '(K B) c h w -> B K c h w', K=K, B=B, h=h, w=w) #e.reshape(B, K, c, h, w)\n","\t\t\tw = F.softmax(f, 1)\n","\t\t\te = (w * e).sum(1)\n","\t\t\tencoder[i] = e\n","\n","\t\t# ---\n","\t\tlast, decoder = self.decoder(encoder)\n","\t\t#print('decoder',[f.shape for f in decoder])\n","\t\t#print('last',last.shape)\n","\t\tlogit = self.logit(last)\n","\n","\t\toutput = {\n","\t\t\t'ink' : torch.sigmoid(logit),\n","\t\t}\n","\t\treturn output\n","\n","\n","def run_check_net():\n","\n","    height,width =  CFG.crop_size, CFG.crop_size\n","    depth = CFG.crop_depth\n","    batch_size = 2\n","\n","    batch = {\n","        'volume' : torch.from_numpy( np.random.choice(256, (batch_size, depth, height, width))).float(),#.cuda()\n","    }\n","    net = Net()#.cuda()\n","\n","    with torch.no_grad():\n","        with torch.cuda.amp.autocast(enabled=True):\n","            output = net(batch)\n","\n","    #---\n","    print('batch')\n","    for k, v in batch.items():\n","        print(f'{k:>32} : {v.shape} ')\n","\n","    print('output')\n","    for k, v in output.items():\n","        print(f'{k:>32} : {v.shape} ')\n","\n","run_check_net()\n","print('net ok !!!')"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T05:30:40.235078Z","iopub.status.busy":"2023-05-14T05:30:40.234343Z","iopub.status.idle":"2023-05-14T05:42:37.077881Z","shell.execute_reply":"2023-05-14T05:42:37.076887Z","shell.execute_reply.started":"2023-05-14T05:30:40.235038Z"},"trusted":true},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/ink-00-weight/run12-ref-encoder-pool-resnet34d-sample4f-00-fold-2a-00002672.model.pth'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 157\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39mfor\u001b[39;00m i,f \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(checkpoint):\n\u001b[1;32m    156\u001b[0m     n \u001b[39m=\u001b[39m Net()\n\u001b[0;32m--> 157\u001b[0m     f \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(f, map_location\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m storage, loc: storage)\n\u001b[1;32m    158\u001b[0m     \u001b[39mprint\u001b[39m(n\u001b[39m.\u001b[39mload_state_dict(f[\u001b[39m'\u001b[39m\u001b[39mstate_dict\u001b[39m\u001b[39m'\u001b[39m], strict\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))  \u001b[39m# True\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     net\u001b[39m.\u001b[39mappend(n)\n","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py:791\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    789\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 791\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    792\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    793\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    796\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py:271\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 271\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    272\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py:252\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[0;32m--> 252\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/ink-00-weight/run12-ref-encoder-pool-resnet34d-sample4f-00-fold-2a-00002672.model.pth'"]}],"source":["# infer here !!!!\n","#https://gist.github.com/janpaul123/ca3477c1db6de4346affca37e0e3d5b0\n","def mask_to_rle(mask):\n","    m = mask.reshape(-1)\n","    #m = np.where(mask > threshold, 1, 0).astype(np.uint8)\n","\n","    s = np.array((m[:-1] == 0) & (m[1:] == 1))\n","    e = np.array((m[:-1] == 1) & (m[1:] == 0))\n","\n","    s_index = np.where(s)[0] + 2\n","    e_index = np.where(e)[0] + 2\n","    length = e_index - s_index\n","    rle = ' '.join(map(str, sum(zip(s_index, length), ())))\n","    return rle\n","\n","def metric_to_text(ink, label):\n","    text = []\n","\n","    p = ink.reshape(-1)\n","    t = label.reshape(-1)\n","    pos = np.log(np.clip(p,1e-7,1))\n","    neg = np.log(np.clip(1-p,1e-7,1))\n","    bce = -(t*pos +(1-t)*neg).mean()\n","    text.append(f'bce={bce:0.5f}')\n","\n","\n","    #print(f'{threshold:0.1f}, {precision:0.3f}, {recall:0.3f}, {fpr:0.3f},  {dice:0.3f},  {score:0.3f}')\n","    text.append('th   prec   recall   fpr   dice   score')\n","    text.append('---------------------------------------')\n","    for threshold in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n","        p = ink.reshape(-1)\n","        t = label.reshape(-1)\n","        p = (p > threshold).astype(np.float32)\n","        t = (t > 0.5).astype(np.float32)\n","\n","        tp = p * t\n","        precision = tp.sum() / (p.sum() + 0.0001)\n","        recall = tp.sum() / t.sum()\n","\n","        fp = p * (1 - t)\n","        fpr = fp.sum() / (1 - t).sum()\n","\n","        beta = 0.5\n","        #  0.2*1/recall + 0.8*1/prec\n","        score = beta * beta / (1 + beta * beta) * 1 / recall + 1 / (1 + beta * beta) * 1 / precision\n","        score = 1 / score\n","\n","        dice = 2 * tp.sum() / (p.sum() + t.sum())\n","\n","        # print(fold, threshold, precision, recall, fpr,  score)\n","        text.append( f'{threshold:0.1f}, {precision:0.3f}, {recall:0.3f}, {fpr:0.3f},  {dice:0.3f},  {score:0.3f}')\n","    text = '\\n'.join(text)\n","    return text\n","\n","def infer_one(net, d):\n","    num_net = len(net)\n","    for i in range(num_net):\n","        net[i] = net[i].cuda()\n","        net[i] = net[i].eval()\n","\n","    #get coord\n","    size   = CFG.crop_size\n","    stride = CFG.stride\n","    H,W,D  = d.volume.shape\n","\n","    x = np.arange(0,W-size+1,stride)\n","    y = np.arange(0,H-size+1,stride)\n","    x,y = np.meshgrid(x,y)\n","    xy  = np.stack([x,y],-1).reshape(-1,2)\n","    print('H,W,len(xy)',H,W,len(xy))\n","\n","    #---\n","    probability = np.zeros((H,W))\n","    count = np.zeros((H,W))\n","\n","    start_timer = timer()\n","    batch_iter = np.array_split(xy, len(xy)//32)\n","    for t, xy0 in enumerate(batch_iter):\n","        #print('\\r', t, len(batch_iter), end='')\n","        crop_size  = CFG.crop_size\n","\n","        volume =[]\n","        for x0,y0 in xy0 :\n","            v = d.volume[y0:y0 + crop_size, x0:x0 + crop_size]\n","            volume.append(v)\n","        volume = np.stack(volume)\n","        volume = np.ascontiguousarray(volume.transpose(0,3,1,2))\n","        volume = volume/255\n","        volume = torch.from_numpy(volume).float().cuda()\n","        ##print(volume.shape)\n","\n","        batch = { 'volume': volume }\n","\n","        k = 0\n","        c = 0\n","        with torch.no_grad():\n","            with torch.cuda.amp.autocast(enabled=True):\n","                for i in range(num_net):\n","                    if 0:\n","                        output = net[i](batch)\n","                        k += output['ink'].data.cpu().numpy()\n","                        c += 1\n","\n","                    #--\n","                    #TTA <todo>\n","                    if CFG.is_tta: #tta \n","                        v = [\n","                            volume,\n","                            torch.rot90(volume, k=1, dims=(-2, -1)),\n","                            torch.rot90(volume, k=2, dims=(-2, -1)),\n","                            torch.rot90(volume, k=3, dims=(-2, -1)),\n","                        ]\n","                        K=len(v)\n","                        batch = {\n","                            'volume': torch.cat(v,0)\n","                        }\n","                        output = net[i](batch)\n","                        ink = output['ink']\n","\n","                        B,_,h,w = volume.shape\n","                        ink = ink.reshape(K, B, 1, h, w)\n","                        ink = [\n","                            ink[0],\n","                            torch.rot90(ink[1], k=-1, dims=(-2, -1)),\n","                            torch.rot90(ink[2], k=-2, dims=(-2, -1)),\n","                            torch.rot90(ink[3], k=-3, dims=(-2, -1)),\n","                        ]\n","                        ink = torch.stack(ink, dim=0)\n","                        ink = ink.mean(0)\n","\n","                        k += ink.data.cpu().numpy()\n","                        c += 1\n","                    #--\n","        k = k/c\n","        ##print(k.shape)\n","\n","        batch_size = len(k)\n","        for b in range(batch_size):\n","            x0,y0 = xy0[b]\n","            probability[y0:y0 + crop_size, x0:x0 + crop_size] += k[b,0]\n","            count[y0:y0 + crop_size, x0:x0 + crop_size] += 1\n","        print(f'\\r @infer_one(): {t} / {len(batch_iter)} : {time_to_str(timer() - start_timer, \"sec\")}', end='', flush=True)\n","    print('')\n","    probability = probability/(count+0.000001)\n","    return probability\n","\n","\n","######################################\n","checkpoint=[\n","    '/kaggle/input/ink-00-weight/run12-ref-encoder-pool-resnet34d-sample4f-00-fold-2a-00002672.model.pth',\n","]\n","\n","#----\n","net = []\n","for i,f in enumerate(checkpoint):\n","    n = Net()\n","    f = torch.load(f, map_location=lambda storage, loc: storage)\n","    print(n.load_state_dict(f['state_dict'], strict=True))  # True\n","    net.append(n)\n","\n","#----\n","submission = defaultdict(list)\n","for t,fragment_id in enumerate(valid_id):\n","    d = read_data1(fragment_id)\n","    \n","    print('==================================')\n","    print('fragment_id', d.fragment_id)\n","    print('\\tmask', d.mask.shape)\n","    print('\\tvolume', d.volume.shape)\n","    print('CFG.stride', CFG.stride)\n","    print('CFG.crop_size', CFG.crop_size)  \n","    print('')\n","\n","    probability = infer_one(net, d)\n","    print('probability', probability.shape)\n","\n","    probability = d.mask*probability\n","    predict = (probability>0.5).astype(np.uint8)\n","    \n","    #----\n","    submission['Id'].append(fragment_id)\n","    submission['Predicted'].append(mask_to_rle(predict))\n","    \n","    #----\n","    probability8 = (probability * 255).astype(np.uint8)\n","    plt.figure(t), plt.imshow(probability8, cmap='gray')\n","    #plt.waitforbuttonpress()\n","    if 'train' in CFG.mode:\n","        text = metric_to_text(probability, d.label)\n","        print(text)\n","    print('')\n","\n","print('')\n","print('CFG.mode', CFG.mode)\n","submit_df = pd.DataFrame.from_dict(submission)\n","submit_df.to_csv('submission.csv', index=False)\n","print(submit_df)\n","print('submission.csv ok!!!')\n","\n","'''\n"," @ read_data(): volume2   1 min 01 sec==================================\n","fragment_id 2a\n","\tmask (9456, 9506)\n","\tvolume (9456, 9506, 12)\n","CFG.stride 56\n","CFG.crop_size 224\n","\n","H,W,len(xy) 9456 9506 27390\n"," @infer_one(): 426 / 427 :  5 min 09 sec\n","probability (9456, 9506)\n","bce=0.20143\n","th   prec   recall   fpr   dice   score\n","---------------------------------------\n","0.1, 0.340, 0.812, 0.182,  0.480,  0.385\n","0.2, 0.470, 0.671, 0.088,  0.553,  0.500\n","0.3, 0.578, 0.556, 0.047,  0.567,  0.573\n","0.4, 0.681, 0.448, 0.024,  0.541,  0.617\n","0.5, 0.780, 0.351, 0.011,  0.484,  0.627\n","0.6, 0.862, 0.259, 0.005,  0.399,  0.588\n","0.7, 0.927, 0.171, 0.002,  0.288,  0.492\n","0.8, 0.970, 0.075, 0.000,  0.140,  0.287\n","0.9, 0.992, 0.006, 0.000,  0.012,  0.029\n","\n","\n","CFG.mode ['train']\n","   Id                                          Predicted\n","0  2a  5602838 1 5612341 5 5621847 6 5631352 7 564085...\n","submission.csv ok!!!\n","\n","'''"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":4}
